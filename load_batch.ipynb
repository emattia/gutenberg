{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-24 23:00:10 __init__.py:190] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 3rd party dependencies\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtune.dev.grpo.data import padded_collate_rl\n",
    "from torchtune import config\n",
    "from torchtune.config._utils import _get_component_from_path\n",
    "from vllm import LLM, SamplingParams\n",
    "from omegaconf import DictConfig\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Custom dependencies\n",
    "from viz import display_prompt, display_responses\n",
    "from load_torchtune_ds import load_gutenberg_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 1\n",
    "rank = 1\n",
    "batch_size = 2\n",
    "grpo_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize tokenizer and configure model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_chkpt_path = os.path.expanduser('~/dev/nebius-experiments/projects/torchtune/trained_models/')\n",
    "# model_path = '/tmp/Llama-3.2-3B-Instruct/'\n",
    "# model_path = '/tmp/checkpoints/llama3_2_3B_grpo_gutenberg/epoch_9'\n",
    "model_path = '/tmp/checkpoints/llama3_2_3B_grpo_gutenberg_rewards_v1/epoch_9'\n",
    "cfg_tokenizer = DictConfig({\n",
    "    '_component_': 'torchtune.models.llama3.llama3_tokenizer',\n",
    "    #'path': os.path.join(root_chkpt_path, model_path, 'original/tokenizer.model'),\n",
    "    'path': os.path.join(model_path, 'original/tokenizer.model'),\n",
    "    'max_seq_len': 'null'\n",
    "})\n",
    "collate_fn = 'torchtune.dev.grpo.data.padded_collate_rl'\n",
    "tokenizer = config.instantiate(cfg_tokenizer)\n",
    "collate_fn = _get_component_from_path(collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4516 passages from 1 files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c8607fbb154f51843e8f7abdddd357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4516 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NOTE: this is what we are replacing from og GRPO scripts.\n",
    "# cfg_dataset = DictConfig({\n",
    "#     '_component_': 'torchtune.dev.grpo.gsm8k.gsm8k_dataset',\n",
    "#     'partition': '3-5/100' \n",
    "# })\n",
    "data_path = os.path.join(os.getcwd(), \"gutenberg_dataset\", \"validation\")\n",
    "if not os.path.exists(data_path):\n",
    "    raise ValueError(\"Did you run the download.py script?\")\n",
    "dataset = load_gutenberg_dataset(tokenizer, data_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda batch: padded_collate_rl(\n",
    "        batch,\n",
    "        padding_idx=tokenizer.pad_id,\n",
    "        ignore_idx=-100,  # CROSS_ENTROPY_IGNORE_IDX\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample batch for inspection/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': tensor([[128000,     32,  21765,  ...,  22103,     25,    220],\n",
       "         [128000,     32,  21765,  ..., 128004, 128004, 128004]]),\n",
       " 'answers': ['victorian (1869)', 'edwardian (1910)']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(dataloader._get_iterator())\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(dataloader._get_iterator())\n",
    "tokens = batch[\"tokens\"]         # tokenized prompts\n",
    "answers = batch[\"answers\"]       # untokenized answers\n",
    "tokens = tokens                  # [batch_size x num_tokens_per_prompt]\n",
    "tokens_ls = tokens.tolist()\n",
    "out = []\n",
    "_prompts = []\n",
    "_answers = []\n",
    "for i in range(tokens.shape[0]):\n",
    "    prompt = tokenizer.decode(tokens_ls[i])\n",
    "    _prompts.extend([prompt] * grpo_size) \n",
    "    answer = answers[i]\n",
    "    _answers.extend([answer] * grpo_size)\n",
    "\n",
    "    ## Uncomment below to view the prompt inline.\n",
    "    # display(HTML(display_prompt(\n",
    "    #     prompt, \n",
    "    #     answer, \n",
    "    #     tokenizer\n",
    "    # )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 03-24 23:00:18 arg_utils.py:1135] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\n",
      "INFO 03-24 23:00:18 config.py:1556] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
      "INFO 03-24 23:00:18 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='/tmp/checkpoints/llama3_2_3B_grpo_gutenberg_rewards_v1/epoch_9', speculative_config=None, tokenizer='/tmp/checkpoints/llama3_2_3B_grpo_gutenberg_rewards_v1/epoch_9', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/tmp/checkpoints/llama3_2_3B_grpo_gutenberg_rewards_v1/epoch_9, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "INFO 03-24 23:00:18 cuda.py:230] Using Flash Attention backend.\n",
      "INFO 03-24 23:00:19 model_runner.py:1110] Starting to load model /tmp/checkpoints/llama3_2_3B_grpo_gutenberg_rewards_v1/epoch_9...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a67a1167fc49e79b6cf331ea662206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-24 23:00:20 model_runner.py:1115] Loading model weights took 6.0160 GB\n",
      "INFO 03-24 23:00:21 worker.py:267] Memory profiling takes 0.54 seconds\n",
      "INFO 03-24 23:00:21 worker.py:267] the current vLLM instance can use total_gpu_memory (79.10GiB) x gpu_memory_utilization (0.90) = 71.19GiB\n",
      "INFO 03-24 23:00:21 worker.py:267] model weights take 6.02GiB; non_torch_memory takes 0.15GiB; PyTorch activation peak memory takes 1.21GiB; the rest of the memory reserved for KV Cache is 63.81GiB.\n",
      "INFO 03-24 23:00:21 executor_base.py:110] # CUDA blocks: 37339, # CPU blocks: 2340\n",
      "INFO 03-24 23:00:21 executor_base.py:115] Maximum concurrency for 131072 tokens per request: 4.56x\n",
      "INFO 03-24 23:00:23 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:09<00:00,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-24 23:00:33 model_runner.py:1562] Graph capturing finished in 10 secs, took 0.29 GiB\n",
      "INFO 03-24 23:00:33 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 13.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(\n",
    "    model=model_path, \n",
    "    task=\"generate\", \n",
    "    trust_remote_code=True,\n",
    "    # tensor_parallel_size=1,\n",
    "    dtype='bfloat16'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward pass / inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per inference call hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 512 # reused later\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.8, \n",
    "    top_p=0.95,\n",
    "    max_tokens=max_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 4/4 [00:01<00:00,  3.74it/s, est. speed input: 2216.98 toks/s, output: 689.05 toks/s]\n"
     ]
    }
   ],
   "source": [
    "output = llm.generate(_prompts, sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Unique to the model/tokenizer\n",
    "# This specific configuration is for meta-llama tokenizers.\n",
    "stop_token_ids = [\n",
    "    128001,\n",
    "    128009,\n",
    "    128008\n",
    "]\n",
    "pad_id = 128004\n",
    "\n",
    "data = []\n",
    "for o in output:\n",
    "    out_tokens = list(o.outputs[0].token_ids)\n",
    "    if len(out_tokens) < max_tokens:\n",
    "        out_tokens += [pad_id] * (max_tokens - len(out_tokens))\n",
    "    data.append(out_tokens)\n",
    "responses=torch.tensor(data, dtype=torch.int32).reshape(batch_size, grpo_size, max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses.shape # [batch_size, grpo_size, generation_max_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define reward function\n",
    "\n",
    "For reward functions we adopt the following workflow. \n",
    "\n",
    "First, define a Python module in the structure `rewards_{id}.py`. The file should have a class called `RewardServer`. The `RewardServer` class should have a method called `batch_shaped_correctness_reward`, with this signature:\n",
    "```python\n",
    "def batch_shaped_correctness_reward(\n",
    "        self,\n",
    "        tokenizer: ModelTokenizer, \n",
    "        completions: torch.Tensor, \n",
    "        answers: List[str],\n",
    "        details_report: bool = False\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, Optional[List[Dict[str, Any]]]]\n",
    "```\n",
    "\n",
    "To use this reward function during training, view the torchtune config file (e.g., `3B_full_grpo_llama_32.yaml`), and set the `reward_fn: {id}` field. For details, see the `grpo_full_finetune_distributed.py` function in this repo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rewards_v0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile rewards_v0.py\n",
    "\n",
    "import re\n",
    "import html\n",
    "from xml.etree import ElementTree as ET\n",
    "from typing import Tuple, List, Dict, Any, Optional\n",
    "\n",
    "import torch\n",
    "from torchtune.modules.transforms.tokenizers import ModelTokenizer\n",
    "\n",
    "# TODO: Scoop this from download_src_data module to ensure consistency.\n",
    "VALID_ERAS = [\n",
    "    \"renaissance\",\n",
    "    \"enlightenment\",\n",
    "    \"victorian\",\n",
    "    \"edwardian\",\n",
    "    \"modern\"\n",
    "]\n",
    "\n",
    "class RewardServer(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def check_outside_text(self, text: str) -> tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        More robust function to detect text outside the required tags.\n",
    "\n",
    "        Args:\n",
    "            text: The text to analyze\n",
    "\n",
    "        Returns:\n",
    "            tuple: (has_outside_text, outside_text)\n",
    "        \"\"\"\n",
    "        # First strip whitespace\n",
    "        text = text.strip()\n",
    "\n",
    "        # Use regex to extract all tag content\n",
    "        pattern = r\"<(think|answer_date|answer_era)>(.*?)</\\1>\"\n",
    "        matches = re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "        # Create a cleaned version for comparison\n",
    "        cleaned_text = text\n",
    "\n",
    "        # Remove all valid tag content\n",
    "        for tag, content in matches:\n",
    "            cleaned_text = cleaned_text.replace(f\"<{tag}>{content}</{tag}>\", \"\", 1)\n",
    "\n",
    "        # Strip whitespace again\n",
    "        cleaned_text = cleaned_text.strip()\n",
    "\n",
    "        return bool(cleaned_text), cleaned_text\n",
    "\n",
    "\n",
    "    def extract_tags(self, text: str) -> dict[str, list[str]]:\n",
    "        \"\"\"\n",
    "        Parse XML-like tags from text, with improved handling for malformed XML.\n",
    "\n",
    "        Args:\n",
    "            text: Text potentially containing XML tags\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with tag content keyed by tag name\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            \"think\": [],\n",
    "            \"answer_era\": [],\n",
    "            \"answer_date\": []\n",
    "        }\n",
    "\n",
    "        # First, try regex method (more robust for malformed XML)\n",
    "        for tag in [\"think\", \"answer_era\", \"answer_date\"]:\n",
    "            pattern = f\"<{tag}>(.*?)</{tag}>\"\n",
    "            matches = re.findall(pattern, text, re.DOTALL)\n",
    "            if matches:\n",
    "                # Trim whitespace from each match\n",
    "                results[tag] = [match.strip() for match in matches]\n",
    "\n",
    "        # If regex found matches, return those\n",
    "        if any(len(v) > 0 for v in results.values()):\n",
    "            return results\n",
    "\n",
    "        # Otherwise try the XML parser as fallback\n",
    "        xml_string = f\"<root>{text}</root>\"\n",
    "        try:\n",
    "            root = ET.fromstring(xml_string)\n",
    "            for tag in [\"think\", \"answer_era\", \"answer_date\"]:\n",
    "                results[tag] = [\n",
    "                    (elem.text.strip() if elem.text else \"\") \n",
    "                    for elem in root.findall(tag)\n",
    "                ]\n",
    "            return results\n",
    "        except ET.ParseError:\n",
    "            # Return the empty results if both methods fail\n",
    "            return results\n",
    "\n",
    "\n",
    "    def shaped_correctness_reward(self, answer: str, completion: str) -> tuple[float, float, Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Reward function for gutenberg_eras_tour task with detailed diagnostics.\n",
    "\n",
    "        Args:\n",
    "            answer: Ground-truth answer string in format \"era (date)\"\n",
    "            completion: Model's unparsed completion string\n",
    "\n",
    "        Returns:\n",
    "            tuple: (reward_score, success_flag, details_dict)\n",
    "        \"\"\"\n",
    "\n",
    "        # Rewards can be negative. Max reward is 100.\n",
    "        # TODO: I've seen some folks speculating rewards in [0, 1] is beneficial.\n",
    "        reward = 0.0\n",
    "        success = 0.0\n",
    "\n",
    "        # Storage for diagnostics.\n",
    "        details = {\n",
    "            \"ground_truth\": {\n",
    "                \"original\": answer,\n",
    "                \"era\": \"\",\n",
    "                \"date\": \"\"\n",
    "            },\n",
    "            \"completion\": completion[:100] + (\"...\" if len(completion) > 100 else \"\"),  # Truncated for readability\n",
    "            \"extracted_tags\": {},\n",
    "            \"format_analysis\": {},\n",
    "            \"content_analysis\": {},\n",
    "            \"reward_components\": [],\n",
    "            \"total_reward\": 0.0,\n",
    "            \"success\": 0.0\n",
    "        }\n",
    "\n",
    "        # Parse the true labels we want the LLM to learn to infer based on its reasoning.\n",
    "        gt_match = re.match(r'([a-z]+)\\s*\\((\\d+)\\)', answer.lower())\n",
    "        if gt_match:\n",
    "            gt_era = gt_match.group(1).strip()\n",
    "            gt_date = gt_match.group(2).strip()\n",
    "        else:\n",
    "            # Fallback if parsing fails\n",
    "            gt_era = answer.lower().strip()\n",
    "            gt_date = \"\"\n",
    "        details[\"ground_truth\"][\"era\"] = gt_era\n",
    "        details[\"ground_truth\"][\"date\"] = gt_date\n",
    "\n",
    "        # Parse content from the LLM's completion.\n",
    "        tags = self.extract_tags(completion)\n",
    "        details[\"extracted_tags\"] = {\n",
    "            \"think\": tags[\"think\"],\n",
    "            \"answer_era\": tags[\"answer_era\"],\n",
    "            \"answer_date\": tags[\"answer_date\"]\n",
    "        }\n",
    "\n",
    "        ### FORMATTING PENALTY ### \n",
    "\n",
    "        # Max reward: 0.\n",
    "        # Min reward: -30.\n",
    "        # Does text exist outside of desired XML format?\n",
    "        has_outside_text, outside_text = self.check_outside_text(completion)\n",
    "        details[\"format_analysis\"][\"has_outside_text\"] = has_outside_text\n",
    "        if has_outside_text:\n",
    "            details[\"format_analysis\"][\"outside_text\"] = outside_text\n",
    "        # Apply significant penalties for text outside tags\n",
    "        if has_outside_text:\n",
    "            # More aggressive penalty for text outside tags\n",
    "            penalty = min(30.0, len(outside_text) * 0.2)\n",
    "            reward -= penalty\n",
    "            details[\"reward_components\"].append({\n",
    "                \"component\": \"outside_text_penalty\",\n",
    "                \"value\": -penalty,\n",
    "                \"reason\": f\"Text found outside required tags: '{outside_text[:30]}...' ({len(outside_text)} chars)\"\n",
    "            })\n",
    "\n",
    "        ### FORMATTING REWARDS ###\n",
    "\n",
    "        ## <think> FORMATTING ##\n",
    "        # Max reward: 10.\n",
    "        # Min reward: -5.\n",
    "        if len(tags[\"think\"]) == 1:\n",
    "            reward += 10.0  # Good reward for having exactly one thinking section\n",
    "            details[\"reward_components\"].append({\n",
    "                \"component\": \"think_tag_format\",\n",
    "                \"value\": 10.0,\n",
    "                \"reason\": \"Correct: Exactly one <think> tag\"\n",
    "            })\n",
    "        elif len(tags[\"think\"]) > 1:\n",
    "            reward += 2.5   # Smaller reward for having thinking, but too many sections\n",
    "            details[\"reward_components\"].append({\n",
    "                \"component\": \"think_tag_format\",\n",
    "                \"value\": 2.5,\n",
    "                \"reason\": f\"Partial: {len(tags['think'])} <think> tags found (expected 1)\"\n",
    "            })\n",
    "        else:\n",
    "            reward -= 5.0   # Penalty for missing thinking section\n",
    "            details[\"reward_components\"].append({\n",
    "                \"component\": \"think_tag_format\",\n",
    "                \"value\": -5.0,\n",
    "                \"reason\": \"Missing <think> tag\"\n",
    "            })\n",
    "\n",
    "        ## <answer_era> FORMATTING ##\n",
    "        # Max reward: 10.\n",
    "        # Min reward: -5.\n",
    "        if len(tags[\"answer_era\"]) == 1:\n",
    "            reward += 10.0  # Increased reward for having exactly one era tag\n",
    "            details[\"reward_components\"].append({\n",
    "                \"component\": \"era_tag_format\",\n",
    "                \"value\": 10.0,\n",
    "                \"reason\": \"Correct: Exactly one <answer_era> tag\"\n",
    "            })\n",
    "        elif len(tags[\"answer_era\"]) > 1:\n",
    "            reward += 2.5   # Some reward for having era tags, but too many\n",
    "            details[\"reward_components\"].append({\n",
    "                \"component\": \"era_tag_format\",\n",
    "                \"value\": 2.5,\n",
    "                \"reason\": f\"Partial: {len(tags['answer_era'])} <answer_era> tags found (expected 1)\"\n",
    "            })\n",
    "        else:\n",
    "            reward -= 10.0  # Stronger penalty for missing era\n",
    "            details[\"reward_components\"].append({\n",
    "                \"component\": \"era_tag_format\",\n",
    "                \"value\": -10.0,\n",
    "                \"reason\": \"Missing <answer_era> tag\"\n",
    "            })\n",
    "            \n",
    "        ## <answer_date> FORMATTING ##\n",
    "        # Max reward: 10.\n",
    "        # Min reward: -5.\n",
    "        if len(tags[\"answer_date\"]) == 1:\n",
    "            reward += 10.0  # Increased reward for having exactly one date tag\n",
    "            details[\"reward_components\"].append({\n",
    "                \"component\": \"date_tag_format\",\n",
    "                \"value\": 10.0,\n",
    "                \"reason\": \"Correct: Exactly one <answer_date> tag\"\n",
    "            })\n",
    "        elif len(tags[\"answer_date\"]) > 1:\n",
    "            reward += 2.5   # Some reward for having date tags, but too many\n",
    "            details[\"reward_components\"].append({\n",
    "                \"component\": \"date_tag_format\",\n",
    "                \"value\": 2.5,\n",
    "                \"reason\": f\"Partial: {len(tags['answer_date'])} <answer_date> tags found (expected 1)\"\n",
    "            })\n",
    "        else:\n",
    "            reward -= 10.0  # Stronger penalty for missing date\n",
    "            details[\"reward_components\"].append({\n",
    "                \"component\": \"date_tag_format\",\n",
    "                \"value\": -10.0,\n",
    "                \"reason\": \"Missing <answer_date> tag\"\n",
    "            })\n",
    "\n",
    "        ## <answer_era> validation rewards ##\n",
    "        # Max reward: 5.\n",
    "        # Min reward: -5.\n",
    "        if tags[\"answer_era\"]:\n",
    "            details[\"content_analysis\"][\"era\"] = {\n",
    "                \"provided\": [era.lower() for era in tags[\"answer_era\"]],\n",
    "                \"valid_eras\": VALID_ERAS,\n",
    "                \"ground_truth\": gt_era\n",
    "            }\n",
    "\n",
    "            # Is LLM-provided era in the valid list?\n",
    "            valid_provided = [era.lower() for era in tags[\"answer_era\"] if era.lower() in VALID_ERAS]\n",
    "            if valid_provided:\n",
    "                reward += 5.0  # Bonus for using a valid era from the list\n",
    "                details[\"reward_components\"].append({\n",
    "                    \"component\": \"era_validation\",\n",
    "                    \"value\": 5.0,\n",
    "                    \"reason\": f\"Used valid era(s): {', '.join(valid_provided)}\"\n",
    "                })\n",
    "            else:\n",
    "                reward -= 5.0  # Penalty for using invalid era\n",
    "                details[\"reward_components\"].append({\n",
    "                    \"component\": \"era_validation\",\n",
    "                    \"value\": -5.0,\n",
    "                    \"reason\": f\"Invalid era(s): {', '.join([era.lower() for era in tags['answer_era']])}\"\n",
    "                })\n",
    "\n",
    "        ## <answer_era> correctness rewards ##\n",
    "        # Max reward: 30.\n",
    "        # Min reward: 0.\n",
    "        if tags[\"answer_era\"]:\n",
    "            exact_match = any(gt_era == attempt.lower().strip() for attempt in tags[\"answer_era\"])\n",
    "            partial_match = any(gt_era in attempt.lower().strip() for attempt in tags[\"answer_era\"])\n",
    "\n",
    "            details[\"content_analysis\"][\"era_match\"] = {\n",
    "                \"exact_match\": exact_match,\n",
    "                \"partial_match\": partial_match\n",
    "            }\n",
    "\n",
    "            if exact_match:\n",
    "                # One of the answer_era tags has the exact right era\n",
    "                reward += 30.0  # Increased reward for correct era\n",
    "                details[\"reward_components\"].append({\n",
    "                    \"component\": \"era_correctness\",\n",
    "                    \"value\": 30.0,\n",
    "                    \"reason\": f\"Correct era: {gt_era}\"\n",
    "                })\n",
    "            elif partial_match:\n",
    "                # One of the answer_era tags contains the right era as a substring\n",
    "                reward += 10.0  # Partial reward\n",
    "                details[\"reward_components\"].append({\n",
    "                    \"component\": \"era_correctness\",\n",
    "                    \"value\": 10.0,\n",
    "                    \"reason\": f\"Partial era match: Contains '{gt_era}'\"\n",
    "                })\n",
    "            else:\n",
    "                details[\"reward_components\"].append({\n",
    "                    \"component\": \"era_correctness\",\n",
    "                    \"value\": 0.0,\n",
    "                    \"reason\": f\"Incorrect era: Expected '{gt_era}'\"\n",
    "                })\n",
    "\n",
    "        ## <answer_date> correctness rewards ##\n",
    "        # Max reward: 30.\n",
    "        # Min reward: -5.\n",
    "        if gt_date and tags[\"answer_date\"]:\n",
    "            try:\n",
    "                gt_year = int(gt_date)\n",
    "\n",
    "                # Parse all dates and track errors\n",
    "                date_attempts = []\n",
    "                valid_dates = []\n",
    "\n",
    "                for attempt in tags[\"answer_date\"]:\n",
    "                    attempt = attempt.strip()\n",
    "                    date_attempts.append(attempt)\n",
    "                    if attempt.isdigit():\n",
    "                        valid_dates.append(int(attempt))\n",
    "\n",
    "                details[\"content_analysis\"][\"date\"] = {\n",
    "                    \"provided\": date_attempts,\n",
    "                    \"valid_dates\": valid_dates,\n",
    "                    \"ground_truth\": gt_year\n",
    "                }\n",
    "\n",
    "                if valid_dates:\n",
    "                    # Find best date attempt (closest to ground truth)\n",
    "                    best_diff = min(abs(date - gt_year) for date in valid_dates)\n",
    "                    best_date = next(date for date in valid_dates if abs(date - gt_year) == best_diff)\n",
    "\n",
    "                    details[\"content_analysis\"][\"date\"][\"best_match\"] = {\n",
    "                        \"value\": best_date,\n",
    "                        \"difference\": best_diff\n",
    "                    }\n",
    "\n",
    "                    # Award based on closest date\n",
    "                    if best_diff == 0:\n",
    "                        # Exact date match\n",
    "                        reward += 30.0  # Increased reward\n",
    "                        details[\"reward_components\"].append({\n",
    "                            \"component\": \"date_correctness\",\n",
    "                            \"value\": 30.0,\n",
    "                            \"reason\": f\"Exact date match: {best_date}\"\n",
    "                        })\n",
    "                    elif best_diff <= 20:\n",
    "                        # Within 20 years\n",
    "                        reward += 20.0  # Increased reward\n",
    "                        details[\"reward_components\"].append({\n",
    "                            \"component\": \"date_correctness\",\n",
    "                            \"value\": 20.0,\n",
    "                            \"reason\": f\"Close date match: {best_date} (within 20 years of {gt_year})\"\n",
    "                        })\n",
    "                    elif best_diff <= 50:\n",
    "                        # Within 50 years\n",
    "                        reward += 10.0\n",
    "                        details[\"reward_components\"].append({\n",
    "                            \"component\": \"date_correctness\",\n",
    "                            \"value\": 10.0,\n",
    "                            \"reason\": f\"Approximate date: {best_date} (within 50 years of {gt_year})\"\n",
    "                        })\n",
    "                    elif best_diff <= 100:\n",
    "                        # Within 100 years\n",
    "                        reward += 5.0\n",
    "                        details[\"reward_components\"].append({\n",
    "                            \"component\": \"date_correctness\",\n",
    "                            \"value\": 5.0,\n",
    "                            \"reason\": f\"Distant date: {best_date} (within 100 years of {gt_year})\"\n",
    "                        })\n",
    "                    else:\n",
    "                        # More than 100 years off\n",
    "                        reward -= 5.0  # Small penalty for very wrong date\n",
    "                        details[\"reward_components\"].append({\n",
    "                            \"component\": \"date_correctness\",\n",
    "                            \"value\": -5.0,\n",
    "                            \"reason\": f\"Incorrect date: {best_date} (more than 100 years from {gt_year})\"\n",
    "                        })\n",
    "                else:\n",
    "                    # No valid numeric dates found\n",
    "                    reward -= 5.0  # Penalty for non-numeric date\n",
    "                    details[\"reward_components\"].append({\n",
    "                        \"component\": \"date_correctness\",\n",
    "                        \"value\": -5.0,\n",
    "                        \"reason\": f\"Non-numeric date(s): {', '.join(date_attempts)}\"\n",
    "                    })\n",
    "\n",
    "            except ValueError as e:\n",
    "                # Penalty for non-numeric date\n",
    "                reward -= 5.0\n",
    "                details[\"reward_components\"].append({\n",
    "                    \"component\": \"date_correctness\",\n",
    "                    \"value\": -5.0,\n",
    "                    \"reason\": f\"Date parsing error: {str(e)}\"\n",
    "                })\n",
    "\n",
    "        ## Success criteria ##\n",
    "        # Both era and date must be correct AND format must be perfect\n",
    "        perfect_format = (\n",
    "            len(tags[\"think\"]) == 1 and \n",
    "            len(tags[\"answer_era\"]) == 1 and \n",
    "            len(tags[\"answer_date\"]) == 1 and\n",
    "            not has_outside_text\n",
    "        )\n",
    "\n",
    "        correct_era = (\n",
    "            tags[\"answer_era\"] and \n",
    "            tags[\"answer_era\"][0].lower().strip() == gt_era\n",
    "        )\n",
    "\n",
    "        correct_date = (\n",
    "            gt_date and\n",
    "            tags[\"answer_date\"] and\n",
    "            tags[\"answer_date\"][0].isdigit() and \n",
    "            abs(int(tags[\"answer_date\"][0]) - int(gt_date)) <= 20\n",
    "        )\n",
    "\n",
    "        details[\"success_criteria\"] = {\n",
    "            \"perfect_format\": perfect_format,\n",
    "            \"correct_era\": correct_era,\n",
    "            \"correct_date\": correct_date\n",
    "        }\n",
    "\n",
    "        if perfect_format and correct_era and correct_date:\n",
    "            reward = 100.0\n",
    "            success = 1.0\n",
    "            details[\"reward_components\"].append({\n",
    "                \"component\": \"perfect_answer\",\n",
    "                \"value\": \"100.0 (overwrites previous)\",\n",
    "                \"reason\": \"Perfect format and correct answers\"\n",
    "            })\n",
    "\n",
    "        # Store final reward and success in details\n",
    "        details[\"total_reward\"] = reward\n",
    "        details[\"success\"] = success\n",
    "\n",
    "        return reward, success, details\n",
    "\n",
    "\n",
    "    def batch_shaped_correctness_reward(\n",
    "        self,\n",
    "        tokenizer: ModelTokenizer, \n",
    "        completions: torch.Tensor, \n",
    "        answers: List[str],\n",
    "        details_report: bool = False\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, Optional[List[Dict[str, Any]]]]:\n",
    "        \"\"\"\n",
    "        Apply the shaped reward function to a batch of completions.\n",
    "        DO NOT change the signature of this function, or it will break the design pattern of how this object method is invoked in grpo_full_finetune_distributed.py.\n",
    "\n",
    "        Args:\n",
    "            tokenizer: Tokenizer for decoding completions\n",
    "            completions: Tensor of token IDs\n",
    "            answers: List of ground truth answers\n",
    "            details_report: Whether to generate detailed diagnostic reports\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (rewards, successes, optional details list)\n",
    "        \"\"\"\n",
    "        batch_size, grpo_size, *_ = completions.shape\n",
    "        rewards = torch.zeros(batch_size, grpo_size, dtype=torch.float32)\n",
    "        successes = torch.zeros(batch_size, grpo_size, dtype=torch.float32)\n",
    "\n",
    "        # Create container for details if requested\n",
    "        details_list = [] if details_report else None\n",
    "\n",
    "        # Process each completion in the batch\n",
    "        for b in range(batch_size):\n",
    "            batch_details = [] if details_report else None\n",
    "\n",
    "            for g in range(grpo_size):\n",
    "                # Decode the completion\n",
    "                text_completion = tokenizer.decode(\n",
    "                    completions[b, g].tolist()\n",
    "                )\n",
    "\n",
    "                # Calculate reward, success, and details\n",
    "                reward, success, details = self.shaped_correctness_reward(\n",
    "                    answer=answers[b], \n",
    "                    completion=text_completion\n",
    "                )\n",
    "\n",
    "                # Store results\n",
    "                rewards[b, g] = reward\n",
    "                successes[b, g] = success\n",
    "\n",
    "                # Store details if requested\n",
    "                if details_report:\n",
    "                    # Add batch and group indices\n",
    "                    details[\"batch_idx\"] = b\n",
    "                    details[\"group_idx\"] = g\n",
    "                    batch_details.append(details)\n",
    "\n",
    "            # Add batch details to the main list\n",
    "            if details_report:\n",
    "                details_list.append(batch_details)\n",
    "\n",
    "        return rewards, successes, details_list\n",
    "\n",
    "\n",
    "    # Helper function to print a readable summary of the details\n",
    "    def print_reward_details_summary(self, details: Dict[str, Any]) -> None:\n",
    "        \"\"\"\n",
    "        Print a human-readable summary of the reward details.\n",
    "\n",
    "        Args:\n",
    "            details: The details dictionary from shaped_correctness_reward\n",
    "        \"\"\"\n",
    "        print(f\"=== Reward Calculation Summary ===\")\n",
    "        print(f\"Ground Truth: Era='{details['ground_truth']['era']}', Date='{details['ground_truth']['date']}'\")\n",
    "        print(f\"Completion: {details['completion']}\")\n",
    "        print(\"\\nExtracted Tags:\")\n",
    "        print(f\"  Think: {len(details['extracted_tags']['think'])} tag(s)\")\n",
    "        print(f\"  Era: {len(details['extracted_tags']['answer_era'])} tag(s)\")\n",
    "        print(f\"  Date: {len(details['extracted_tags']['answer_date'])} tag(s)\")\n",
    "\n",
    "        print(\"\\nFormat Analysis:\")\n",
    "        if details['format_analysis'].get('has_outside_text', False):\n",
    "            print(f\"  ❌ Text outside tags: {details['format_analysis']['outside_text']}\")\n",
    "        else:\n",
    "            print(f\"  ✓ No text outside tags\")\n",
    "\n",
    "        print(\"\\nContent Analysis:\")\n",
    "        if 'era' in details['content_analysis']:\n",
    "            print(f\"  Era provided: {details['content_analysis']['era']['provided']}\")\n",
    "            match_status = \"❌ No match\"\n",
    "            if details['content_analysis'].get('era_match', {}).get('exact_match', False):\n",
    "                match_status = \"✓ Exact match\"\n",
    "            elif details['content_analysis'].get('era_match', {}).get('partial_match', False):\n",
    "                match_status = \"~ Partial match\"\n",
    "            print(f\"  Era match: {match_status}\")\n",
    "\n",
    "        if 'date' in details['content_analysis']:\n",
    "            print(f\"  Date provided: {details['content_analysis']['date']['provided']}\")\n",
    "            if 'best_match' in details['content_analysis']['date']:\n",
    "                best = details['content_analysis']['date']['best_match']\n",
    "                print(f\"  Best date: {best['value']} (diff: {best['difference']} years)\")\n",
    "\n",
    "        print(\"\\nReward Components:\")\n",
    "        for component in details['reward_components']:\n",
    "            print(f\"  {component['component']}: {component['value']} - {component['reason']}\")\n",
    "\n",
    "        print(f\"\\nTotal Reward: {details['total_reward']}\")\n",
    "        print(f\"Success: {details['success']}\")\n",
    "\n",
    "        if 'success_criteria' in details:\n",
    "            criteria = details['success_criteria']\n",
    "            print(\"\\nSuccess Criteria:\")\n",
    "            print(f\"  Format perfect: {'✓' if criteria['perfect_format'] else '❌'}\")\n",
    "            print(f\"  Era correct: {'✓' if criteria['correct_era'] else '❌'}\")\n",
    "            print(f\"  Date correct: {'✓' if criteria['correct_date'] else '❌'}\")\n",
    "\n",
    "        print(\"================================\")\n",
    "\n",
    "    def display_responses(\n",
    "        self,\n",
    "        responses: torch.Tensor,\n",
    "        tokenizer: ModelTokenizer,\n",
    "        grpo_size: int,\n",
    "        advantages: Optional[torch.Tensor] = None,\n",
    "        rewards: Optional[torch.Tensor] = None,\n",
    "        successes: Optional[torch.Tensor] = None,\n",
    "        details: Optional[List[List[Dict[str, Any]]]] = None,\n",
    "        show_n: Optional[int] = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Display responses with rewards, advantages, and detailed diagnostics in a visually appealing format.\n",
    "        \n",
    "        Args:\n",
    "            responses: Tensor of token IDs\n",
    "            tokenizer: Tokenizer for decoding responses\n",
    "            grpo_size: Size of the policy optimization group\n",
    "            advantages: Optional tensor of advantages\n",
    "            rewards: Optional tensor of rewards\n",
    "            successes: Optional tensor of successes\n",
    "            details: Optional list of reward calculation details\n",
    "            show_n: Optional maximum number of responses to display\n",
    "            \n",
    "        Returns:\n",
    "            HTML string for displaying the responses\n",
    "        \"\"\"\n",
    "        batch_size = responses.shape[0]\n",
    "        \n",
    "        # Helper function to safely get values from tensors with different shapes\n",
    "        def get_item_value(tensor, batch_idx, group_idx):\n",
    "            if tensor is None:\n",
    "                return None\n",
    "            \n",
    "            if tensor.dim() == 1:\n",
    "                # Handle 1D tensor [grpo_size]\n",
    "                return tensor[group_idx].item()\n",
    "            else:\n",
    "                # Handle 2D tensor [batch_size, grpo_size]\n",
    "                return tensor[batch_idx][group_idx].item()\n",
    "        \n",
    "        html_output = \"\"\"\n",
    "        <style>\n",
    "            .response-container {\n",
    "                margin: 20px 0;\n",
    "                border: 1px solid #C4C7AC;\n",
    "                border-radius: 8px;\n",
    "                overflow: hidden;\n",
    "                box-shadow: 0 2px 5px rgba(0,0,0,0.05);\n",
    "                font-family: 'Courier New', monospace;\n",
    "                max-width: 100%;\n",
    "            }\n",
    "            .response-header {\n",
    "                background-color: #F0EBE5;\n",
    "                padding: 10px 15px;\n",
    "                font-size: 16px;\n",
    "                font-weight: bold;\n",
    "                border-bottom: 1px solid #C4C7AC;\n",
    "                color: #4A4A67;\n",
    "                display: flex;\n",
    "                justify-content: space-between;\n",
    "                align-items: center;\n",
    "            }\n",
    "            .response-body {\n",
    "                background-color: #ffffff;\n",
    "                color: #4A4A67;\n",
    "                padding: 15px;\n",
    "                white-space: pre-wrap;\n",
    "                word-wrap: break-word;\n",
    "                line-height: 1.6;\n",
    "                font-size: 14px;\n",
    "            }\n",
    "            .think-tag {\n",
    "                color: #BE6A1A;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .answer-tag {\n",
    "                color: #2C6846;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .answer-era-tag {\n",
    "                color: #2C6846;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .answer-date-tag {\n",
    "                color: #2C6846;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .metrics-container {\n",
    "                background-color: #F0EBE5;\n",
    "                border-top: 1px solid #C4C7AC;\n",
    "                padding: 10px 15px;\n",
    "            }\n",
    "            .metric-label {\n",
    "                color: #4A4A67;\n",
    "            }\n",
    "            .metric-score {\n",
    "                font-family: monospace;\n",
    "                font-weight: bold;\n",
    "                padding: 2px 8px;\n",
    "                border-radius: 4px;\n",
    "                display: inline-block;\n",
    "                margin-right: 8px;\n",
    "            }\n",
    "            .score-high {\n",
    "                background-color: #D3EFE0;\n",
    "                color: #177350;\n",
    "            }\n",
    "            .score-medium {\n",
    "                background-color: #FCF1D6;\n",
    "                color: #BE6A1A;\n",
    "            }\n",
    "            .score-low {\n",
    "                background-color: #FAD9D8;\n",
    "                color: #C5393A;\n",
    "            }\n",
    "            .success-badge {\n",
    "                background-color: #177350;\n",
    "                color: white;\n",
    "                padding: 3px 8px;\n",
    "                border-radius: 4px;\n",
    "                font-size: 12px;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .failure-badge {\n",
    "                background-color: #C5393A;\n",
    "                color: white;\n",
    "                padding: 3px 8px;\n",
    "                border-radius: 4px;\n",
    "                font-size: 12px;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .metrics-toggle {\n",
    "                cursor: pointer;\n",
    "                color: #3F7DC9;\n",
    "                text-decoration: underline;\n",
    "                font-size: 12px;\n",
    "                margin-top: 5px;\n",
    "                display: inline-block;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .details-container {\n",
    "                display: none;\n",
    "                margin-top: 10px;\n",
    "                border-top: 1px solid #C4C7AC;\n",
    "                padding-top: 10px;\n",
    "            }\n",
    "            \n",
    "            /* Reward details styling */\n",
    "            .reward-component {\n",
    "                margin-bottom: 10px;\n",
    "                padding: 8px;\n",
    "                border-radius: 4px;\n",
    "                background-color: #f8f9fa;\n",
    "            }\n",
    "            .component-name {\n",
    "                font-weight: bold;\n",
    "                color: #4A4A67;\n",
    "            }\n",
    "            .component-value {\n",
    "                font-family: monospace;\n",
    "                padding: 2px 4px;\n",
    "                border-radius: 3px;\n",
    "            }\n",
    "            .component-value-positive {\n",
    "                background-color: #D3EFE0;\n",
    "                color: #177350;\n",
    "            }\n",
    "            .component-value-negative {\n",
    "                background-color: #FAD9D8;\n",
    "                color: #C5393A;\n",
    "            }\n",
    "            .component-reason {\n",
    "                font-size: 0.9em;\n",
    "                color: #555;\n",
    "                margin-top: 4px;\n",
    "            }\n",
    "            .check-success {\n",
    "                color: #177350;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .check-fail {\n",
    "                color: #C5393A;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .batch-header {\n",
    "                margin: 30px 0 10px 0;\n",
    "                padding: 5px 10px;\n",
    "                background-color: #E5E7D9;\n",
    "                border-left: 4px solid #4A4A67;\n",
    "                color: #4A4A67;\n",
    "                font-size: 18px;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "        </style>\n",
    "        \n",
    "        <script>\n",
    "        function toggleDetails(batchIdx, groupIdx) {\n",
    "            var detailsId = 'details-' + batchIdx + '-' + groupIdx;\n",
    "            var details = document.getElementById(detailsId);\n",
    "            var buttonId = 'toggle-' + batchIdx + '-' + groupIdx;\n",
    "            var toggleBtn = document.getElementById(buttonId);\n",
    "            \n",
    "            if (details) {\n",
    "                if (details.style.display === 'none' || details.style.display === '') {\n",
    "                    details.style.display = 'block';\n",
    "                    if (toggleBtn) toggleBtn.innerText = 'Hide Details';\n",
    "                } else {\n",
    "                    details.style.display = 'none';\n",
    "                    if (toggleBtn) toggleBtn.innerText = 'Show Details';\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        </script>\n",
    "        \"\"\"\n",
    "        \n",
    "        if show_n is not None:\n",
    "            grpo_size = min(grpo_size, show_n)\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            html_output += f'<div class=\"batch-header\">Batch #{b+1}</div>'\n",
    "            \n",
    "            for g in range(grpo_size):\n",
    "                # Decode the response\n",
    "                response_text = tokenizer.decode(responses[b, g].tolist())\n",
    "                \n",
    "                # Determine if this response succeeded\n",
    "                success_value = get_item_value(successes, b, g) if successes is not None else None\n",
    "                is_successful = success_value == 1.0 if success_value is not None else None\n",
    "                \n",
    "                # Get reward and advantage if available\n",
    "                reward_value = get_item_value(rewards, b, g) if rewards is not None else None\n",
    "                advantage_value = get_item_value(advantages, b, g) if advantages is not None else None\n",
    "                \n",
    "                # Start response container\n",
    "                html_output += f'<div class=\"response-container\">'\n",
    "                \n",
    "                # Response header\n",
    "                html_output += f'<div class=\"response-header\">'\n",
    "                html_output += f'<div>Response #{g+1}</div>'\n",
    "                \n",
    "                # Add success/fail badge if available\n",
    "                if is_successful is not None:\n",
    "                    if is_successful:\n",
    "                        html_output += f'<div class=\"success-badge\">SUCCESS</div>'\n",
    "                    else:\n",
    "                        html_output += f'<div class=\"failure-badge\">FAIL</div>'\n",
    "                \n",
    "                html_output += '</div>'  # End response header\n",
    "                \n",
    "                # Response body with tag highlighting\n",
    "                html_output += f'<div class=\"response-body\">'\n",
    "                \n",
    "                # Escape HTML but preserve line breaks\n",
    "                escaped_text = html.escape(response_text).replace('\\n', '<br>')\n",
    "                \n",
    "                # Highlight tags\n",
    "                escaped_text = re.sub(\n",
    "                    r'&lt;think&gt;(.+?)&lt;/think&gt;',\n",
    "                    r'<span class=\"think-tag\">&lt;think&gt;</span>\\1<span class=\"think-tag\">&lt;/think&gt;</span>',\n",
    "                    escaped_text,\n",
    "                    flags=re.DOTALL\n",
    "                )\n",
    "                \n",
    "                escaped_text = re.sub(\n",
    "                    r'&lt;answer_era&gt;(.+?)&lt;/answer_era&gt;',\n",
    "                    r'<span class=\"answer-era-tag\">&lt;answer_era&gt;</span>\\1<span class=\"answer-era-tag\">&lt;/answer_era&gt;</span>',\n",
    "                    escaped_text\n",
    "                )\n",
    "                \n",
    "                escaped_text = re.sub(\n",
    "                    r'&lt;answer_date&gt;(.+?)&lt;/answer_date&gt;',\n",
    "                    r'<span class=\"answer-date-tag\">&lt;answer_date&gt;</span>\\1<span class=\"answer-date-tag\">&lt;/answer_date&gt;</span>',\n",
    "                    escaped_text\n",
    "                )\n",
    "                \n",
    "                html_output += escaped_text\n",
    "                html_output += '</div>'  # End response body\n",
    "                \n",
    "                # Metrics container\n",
    "                if reward_value is not None or advantage_value is not None:\n",
    "                    html_output += f'<div class=\"metrics-container\">'\n",
    "                    \n",
    "                    # Determine score class based on reward value\n",
    "                    score_class = \"score-high\" if reward_value and reward_value >= 80 else \\\n",
    "                                \"score-medium\" if reward_value and reward_value >= 30 else \\\n",
    "                                \"score-low\"\n",
    "                    \n",
    "                    # Display reward\n",
    "                    if reward_value is not None:\n",
    "                        html_output += f'<div><strong class=\"metric-label\">Reward:</strong> <span class=\"metric-score {score_class}\">{reward_value:.1f}</span></div>'\n",
    "                    \n",
    "                    # Display advantage\n",
    "                    if advantage_value is not None:\n",
    "                        adv_class = \"score-high\" if advantage_value > 0 else \"score-low\"\n",
    "                        html_output += f'<div><strong class=\"metric-label\">Advantage:</strong> <span class=\"metric-score {adv_class}\">{advantage_value:.1f}</span></div>'\n",
    "                    \n",
    "                    # Add details toggle if available\n",
    "                    if details is not None and b < len(details) and g < len(details[b]):\n",
    "                        html_output += f'<a id=\"toggle-{b}-{g}\" class=\"metrics-toggle\" onclick=\"toggleDetails({b}, {g})\">Show Details</a>'\n",
    "                        html_output += f'<div id=\"details-{b}-{g}\" class=\"details-container\">'\n",
    "                        \n",
    "                        # Format reward details\n",
    "                        detail_data = details[b][g]\n",
    "                        \n",
    "                        # Ground truth\n",
    "                        html_output += f'<div style=\"margin-bottom: 15px;\">'\n",
    "                        html_output += f'<div><strong>Ground Truth:</strong> Era=\\'{detail_data[\"ground_truth\"][\"era\"]}\\', Date=\\'{detail_data[\"ground_truth\"][\"date\"]}\\'</div>'\n",
    "                        html_output += f'</div>'\n",
    "                        \n",
    "                        # Extracted tags\n",
    "                        html_output += f'<div style=\"margin-bottom: 15px;\">'\n",
    "                        html_output += f'<div><strong>Extracted Tags:</strong></div>'\n",
    "                        html_output += f'<ul style=\"margin-top: 5px; padding-left: 20px;\">'\n",
    "                        html_output += f'<li>Think: {len(detail_data[\"extracted_tags\"][\"think\"])} tag(s)</li>'\n",
    "                        html_output += f'<li>Era: {len(detail_data[\"extracted_tags\"][\"answer_era\"])} tag(s)</li>'\n",
    "                        html_output += f'<li>Date: {len(detail_data[\"extracted_tags\"][\"answer_date\"])} tag(s)</li>'\n",
    "                        html_output += f'</ul>'\n",
    "                        html_output += f'</div>'\n",
    "                        \n",
    "                        # Format analysis\n",
    "                        html_output += f'<div style=\"margin-bottom: 15px;\">'\n",
    "                        html_output += f'<div><strong>Format Analysis:</strong></div>'\n",
    "                        \n",
    "                        if detail_data['format_analysis'].get('has_outside_text', False):\n",
    "                            outside_text = html.escape(detail_data['format_analysis']['outside_text'])\n",
    "                            html_output += f'<div class=\"check-fail\">❌ Text outside tags: \"{outside_text}\"</div>'\n",
    "                        else:\n",
    "                            html_output += f'<div class=\"check-success\">✓ No text outside tags</div>'\n",
    "                        \n",
    "                        html_output += f'</div>'\n",
    "                        \n",
    "                        # Content analysis\n",
    "                        if 'content_analysis' in detail_data:\n",
    "                            html_output += f'<div style=\"margin-bottom: 15px;\">'\n",
    "                            html_output += f'<div><strong>Content Analysis:</strong></div>'\n",
    "                            \n",
    "                            # Era analysis\n",
    "                            if 'era' in detail_data['content_analysis']:\n",
    "                                provided_eras = ', '.join([f\"'{era}'\" for era in detail_data['content_analysis']['era']['provided']])\n",
    "                                html_output += f'<div style=\"margin-top: 5px;\"><strong>Era provided:</strong> {provided_eras}</div>'\n",
    "                                \n",
    "                                match_status = \"\"\n",
    "                                if detail_data['content_analysis'].get('era_match', {}).get('exact_match', False):\n",
    "                                    match_status = f'<span class=\"check-success\">✓ Exact match</span>'\n",
    "                                elif detail_data['content_analysis'].get('era_match', {}).get('partial_match', False):\n",
    "                                    match_status = f'<span style=\"color: #BE6A1A; font-weight: bold;\">~ Partial match</span>'\n",
    "                                else:\n",
    "                                    match_status = f'<span class=\"check-fail\">❌ No match</span>'\n",
    "                                \n",
    "                                html_output += f'<div><strong>Era match:</strong> {match_status}</div>'\n",
    "                            \n",
    "                            # Date analysis\n",
    "                            if 'date' in detail_data['content_analysis']:\n",
    "                                provided_dates = ', '.join([f\"'{date}'\" for date in detail_data['content_analysis']['date']['provided']])\n",
    "                                html_output += f'<div style=\"margin-top: 5px;\"><strong>Date provided:</strong> {provided_dates}</div>'\n",
    "                                \n",
    "                                if 'best_match' in detail_data['content_analysis']['date']:\n",
    "                                    best = detail_data['content_analysis']['date']['best_match']\n",
    "                                    diff_class = \"check-success\" if best['difference'] <= 20 else \\\n",
    "                                                (\"color: #BE6A1A; font-weight: bold;\" if best['difference'] <= 50 else \"check-fail\")\n",
    "                                    \n",
    "                                    html_output += f'<div><strong>Best date:</strong> {best[\"value\"]} <span style=\"{diff_class}\">(diff: {best[\"difference\"]} years)</span></div>'\n",
    "                            \n",
    "                            html_output += f'</div>'\n",
    "                        \n",
    "                        # Reward components table\n",
    "                        html_output += f'<div style=\"margin-bottom: 15px;\">'\n",
    "                        html_output += f'<div><strong>Reward Components:</strong></div>'\n",
    "                        html_output += f'<div style=\"margin-top: 10px;\">'\n",
    "                        \n",
    "                        for component in detail_data['reward_components']:\n",
    "                            component_name = component['component']\n",
    "                            value = component['value']\n",
    "                            reason = component['reason']\n",
    "                            \n",
    "                            # Determine CSS class based on value\n",
    "                            try:\n",
    "                                value_float = float(str(value).replace(\"(overwrites previous)\", \"\"))\n",
    "                                value_class = \"component-value-positive\" if value_float > 0 else \"component-value-negative\"\n",
    "                            except:\n",
    "                                value_class = \"\"\n",
    "                            \n",
    "                            html_output += f'<div class=\"reward-component\">'\n",
    "                            html_output += f'<div><span class=\"component-name\">{component_name}:</span> <span class=\"component-value {value_class}\">{value}</span></div>'\n",
    "                            html_output += f'<div class=\"component-reason\">{reason}</div>'\n",
    "                            html_output += f'</div>'\n",
    "                        \n",
    "                        html_output += f'</div>'\n",
    "                        html_output += f'</div>'\n",
    "                        \n",
    "                        # Success criteria\n",
    "                        if 'success_criteria' in detail_data:\n",
    "                            criteria = detail_data['success_criteria']\n",
    "                            html_output += f'<div style=\"margin-bottom: 15px;\">'\n",
    "                            html_output += f'<div><strong>Success Criteria:</strong></div>'\n",
    "                            html_output += f'<ul style=\"margin-top: 5px; padding-left: 20px;\">'\n",
    "                            \n",
    "                            html_output += f'<li><span class=\"{\"check-success\" if criteria[\"perfect_format\"] else \"check-fail\"}\">{(\"✓\" if criteria[\"perfect_format\"] else \"❌\")} Format perfect</span></li>'\n",
    "                            html_output += f'<li><span class=\"{\"check-success\" if criteria[\"correct_era\"] else \"check-fail\"}\">{(\"✓\" if criteria[\"correct_era\"] else \"❌\")} Era correct</span></li>'\n",
    "                            html_output += f'<li><span class=\"{\"check-success\" if criteria[\"correct_date\"] else \"check-fail\"}\">{(\"✓\" if criteria[\"correct_date\"] else \"❌\")} Date correct</span></li>'\n",
    "                            \n",
    "                            html_output += f'</ul>'\n",
    "                            html_output += f'</div>'\n",
    "                        \n",
    "                        # Total reward summary\n",
    "                        html_output += f'<div style=\"margin-top: 15px; padding-top: 10px; border-top: 1px solid #C4C7AC;\">'\n",
    "                        html_output += f'<div><strong>Total Reward:</strong> <span class=\"{\"score-high\" if detail_data[\"total_reward\"] > 0 else \"score-low\"}\">{detail_data[\"total_reward\"]}</span></div>'\n",
    "                        html_output += f'<div><strong>Success:</strong> <span class=\"{\"score-high\" if detail_data[\"success\"] > 0 else \"score-low\"}\">{detail_data[\"success\"]}</span></div>'\n",
    "                        html_output += f'</div>'\n",
    "                        \n",
    "                        html_output += f'</div>'  # End details container\n",
    "                    \n",
    "                    html_output += f'</div>'  # End metrics container\n",
    "                \n",
    "                html_output += f'</div>'  # End response container\n",
    "        \n",
    "        return html_output\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rewards_v0 import RewardServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RewardServer()\n",
    "rewards, successes, details = rs.batch_shaped_correctness_reward(     \n",
    "  tokenizer=tokenizer,      \n",
    "  completions=responses,      \n",
    "  answers=_answers,\n",
    "  details_report=True  # Enables detailed diagnostics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Reward Calculation Summary ===\n",
      "Ground Truth: Era='modern', Date='1940'\n",
      "Completion:  <think>The French corsairs operated actively in the sixteenth century, with a significant presence ...\n",
      "\n",
      "Extracted Tags:\n",
      "  Think: 1 tag(s)\n",
      "  Era: 1 tag(s)\n",
      "  Date: 1 tag(s)\n",
      "\n",
      "Format Analysis:\n",
      "  ✓ No text outside tags\n",
      "\n",
      "Content Analysis:\n",
      "  Era provided: ['renaissance']\n",
      "  Era match: ❌ No match\n",
      "  Date provided: ['1500']\n",
      "  Best date: 1500 (diff: 440 years)\n",
      "\n",
      "Reward Components:\n",
      "  think_tag_format: 10.0 - Correct: Exactly one <think> tag\n",
      "  era_tag_format: 10.0 - Correct: Exactly one <answer_era> tag\n",
      "  date_tag_format: 10.0 - Correct: Exactly one <answer_date> tag\n",
      "  era_validation: 5.0 - Used valid era(s): renaissance\n",
      "  era_correctness: 0.0 - Incorrect era: Expected 'modern'\n",
      "  date_correctness: -5.0 - Incorrect date: 1500 (more than 100 years from 1940)\n",
      "\n",
      "Total Reward: 30.0\n",
      "Success: 0.0\n",
      "\n",
      "Success Criteria:\n",
      "  Format perfect: ✓\n",
      "  Era correct: ❌\n",
      "  Date correct: ❌\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "batch_idx = 0\n",
    "group_member_idx = 0\n",
    "rs.print_reward_details_summary(details[batch_idx][group_member_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[30., 30.],\n",
       "        [20., 30.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "advantages = (rewards - rewards.mean(1, keepdim=True)) / (\n",
    "    rewards.std(1, keepdim=True) + 1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000],\n",
       "        [-0.7071,  0.7071]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .response-container {\n",
       "                margin: 20px 0;\n",
       "                border: 1px solid #C4C7AC;\n",
       "                border-radius: 8px;\n",
       "                overflow: hidden;\n",
       "                box-shadow: 0 2px 5px rgba(0,0,0,0.05);\n",
       "                font-family: 'Courier New', monospace;\n",
       "                max-width: 100%;\n",
       "            }\n",
       "            .response-header {\n",
       "                background-color: #F0EBE5;\n",
       "                padding: 10px 15px;\n",
       "                font-size: 16px;\n",
       "                font-weight: bold;\n",
       "                border-bottom: 1px solid #C4C7AC;\n",
       "                color: #4A4A67;\n",
       "                display: flex;\n",
       "                justify-content: space-between;\n",
       "                align-items: center;\n",
       "            }\n",
       "            .response-body {\n",
       "                background-color: #ffffff;\n",
       "                color: #4A4A67;\n",
       "                padding: 15px;\n",
       "                white-space: pre-wrap;\n",
       "                word-wrap: break-word;\n",
       "                line-height: 1.6;\n",
       "                font-size: 14px;\n",
       "            }\n",
       "            .think-tag {\n",
       "                color: #BE6A1A;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            .answer-tag {\n",
       "                color: #2C6846;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            .answer-era-tag {\n",
       "                color: #2C6846;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            .answer-date-tag {\n",
       "                color: #2C6846;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            .metrics-container {\n",
       "                background-color: #F0EBE5;\n",
       "                border-top: 1px solid #C4C7AC;\n",
       "                padding: 10px 15px;\n",
       "            }\n",
       "            .metric-label {\n",
       "                color: #4A4A67;\n",
       "            }\n",
       "            .metric-score {\n",
       "                font-family: monospace;\n",
       "                font-weight: bold;\n",
       "                padding: 2px 8px;\n",
       "                border-radius: 4px;\n",
       "                display: inline-block;\n",
       "                margin-right: 8px;\n",
       "            }\n",
       "            .score-high {\n",
       "                background-color: #D3EFE0;\n",
       "                color: #177350;\n",
       "            }\n",
       "            .score-medium {\n",
       "                background-color: #FCF1D6;\n",
       "                color: #BE6A1A;\n",
       "            }\n",
       "            .score-low {\n",
       "                background-color: #FAD9D8;\n",
       "                color: #C5393A;\n",
       "            }\n",
       "            .success-badge {\n",
       "                background-color: #177350;\n",
       "                color: white;\n",
       "                padding: 3px 8px;\n",
       "                border-radius: 4px;\n",
       "                font-size: 12px;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            .failure-badge {\n",
       "                background-color: #C5393A;\n",
       "                color: white;\n",
       "                padding: 3px 8px;\n",
       "                border-radius: 4px;\n",
       "                font-size: 12px;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            .metrics-toggle {\n",
       "                cursor: pointer;\n",
       "                color: #3F7DC9;\n",
       "                text-decoration: underline;\n",
       "                font-size: 12px;\n",
       "                margin-top: 5px;\n",
       "                display: inline-block;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            .details-container {\n",
       "                display: none;\n",
       "                margin-top: 10px;\n",
       "                border-top: 1px solid #C4C7AC;\n",
       "                padding-top: 10px;\n",
       "            }\n",
       "\n",
       "            /* Reward details styling */\n",
       "            .reward-component {\n",
       "                margin-bottom: 10px;\n",
       "                padding: 8px;\n",
       "                border-radius: 4px;\n",
       "                background-color: #f8f9fa;\n",
       "            }\n",
       "            .component-name {\n",
       "                font-weight: bold;\n",
       "                color: #4A4A67;\n",
       "            }\n",
       "            .component-value {\n",
       "                font-family: monospace;\n",
       "                padding: 2px 4px;\n",
       "                border-radius: 3px;\n",
       "            }\n",
       "            .component-value-positive {\n",
       "                background-color: #D3EFE0;\n",
       "                color: #177350;\n",
       "            }\n",
       "            .component-value-negative {\n",
       "                background-color: #FAD9D8;\n",
       "                color: #C5393A;\n",
       "            }\n",
       "            .component-reason {\n",
       "                font-size: 0.9em;\n",
       "                color: #555;\n",
       "                margin-top: 4px;\n",
       "            }\n",
       "            .check-success {\n",
       "                color: #177350;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            .check-fail {\n",
       "                color: #C5393A;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            .batch-header {\n",
       "                margin: 30px 0 10px 0;\n",
       "                padding: 5px 10px;\n",
       "                background-color: #E5E7D9;\n",
       "                border-left: 4px solid #4A4A67;\n",
       "                color: #4A4A67;\n",
       "                font-size: 18px;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "        </style>\n",
       "\n",
       "        <script>\n",
       "        function toggleDetails(batchIdx, groupIdx) {\n",
       "            var detailsId = 'details-' + batchIdx + '-' + groupIdx;\n",
       "            var details = document.getElementById(detailsId);\n",
       "            var buttonId = 'toggle-' + batchIdx + '-' + groupIdx;\n",
       "            var toggleBtn = document.getElementById(buttonId);\n",
       "\n",
       "            if (details) {\n",
       "                if (details.style.display === 'none' || details.style.display === '') {\n",
       "                    details.style.display = 'block';\n",
       "                    if (toggleBtn) toggleBtn.innerText = 'Hide Details';\n",
       "                } else {\n",
       "                    details.style.display = 'none';\n",
       "                    if (toggleBtn) toggleBtn.innerText = 'Show Details';\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "        </script>\n",
       "        <div class=\"batch-header\">Batch #1</div><div class=\"response-container\"><div class=\"response-header\"><div>Response #1</div><div class=\"failure-badge\">FAIL</div></div><div class=\"response-body\"> <span class=\"think-tag\">&lt;think&gt;</span>The French corsairs operated actively in the sixteenth century, with a significant presence near Cape St Vincent and the Azores, and their exploits were feared by the Spanish, as evident from Columbus&#x27;s declaration. However, the system of armed convoys and the Spanish presence in European waters limited their successes, forcing them to shift their operations to American waters. The historical records from this period are full of references to French attacks on Spanish colonies in the Americas. Therefore, based on the historical evidence and the transitions of French corsairs&#x27; activities, this text suggests that the historical era is the Renaissance era and the approximate date is before 1500, but also heavily influenced by the early modern period, and it is reasonable to approximate the date to be around 1500.<span class=\"think-tag\">&lt;/think&gt;</span> <span class=\"answer-date-tag\">&lt;answer_date&gt;</span>1500<span class=\"answer-date-tag\">&lt;/answer_date&gt;</span> <span class=\"answer-era-tag\">&lt;answer_era&gt;</span>renaissance<span class=\"answer-era-tag\">&lt;/answer_era&gt;</span></div><div class=\"metrics-container\"><div><strong class=\"metric-label\">Reward:</strong> <span class=\"metric-score score-medium\">30.0</span></div><div><strong class=\"metric-label\">Advantage:</strong> <span class=\"metric-score score-low\">0.0</span></div><a id=\"toggle-0-0\" class=\"metrics-toggle\" onclick=\"toggleDetails(0, 0)\">Show Details</a><div id=\"details-0-0\" class=\"details-container\"><div style=\"margin-bottom: 15px;\"><div><strong>Ground Truth:</strong> Era='modern', Date='1940'</div></div><div style=\"margin-bottom: 15px;\"><div><strong>Extracted Tags:</strong></div><ul style=\"margin-top: 5px; padding-left: 20px;\"><li>Think: 1 tag(s)</li><li>Era: 1 tag(s)</li><li>Date: 1 tag(s)</li></ul></div><div style=\"margin-bottom: 15px;\"><div><strong>Format Analysis:</strong></div><div class=\"check-success\">✓ No text outside tags</div></div><div style=\"margin-bottom: 15px;\"><div><strong>Content Analysis:</strong></div><div style=\"margin-top: 5px;\"><strong>Era provided:</strong> 'renaissance'</div><div><strong>Era match:</strong> <span class=\"check-fail\">❌ No match</span></div><div style=\"margin-top: 5px;\"><strong>Date provided:</strong> '1500'</div><div><strong>Best date:</strong> 1500 <span style=\"check-fail\">(diff: 440 years)</span></div></div><div style=\"margin-bottom: 15px;\"><div><strong>Reward Components:</strong></div><div style=\"margin-top: 10px;\"><div class=\"reward-component\"><div><span class=\"component-name\">think_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <think> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <answer_era> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">date_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <answer_date> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_validation:</span> <span class=\"component-value component-value-positive\">5.0</span></div><div class=\"component-reason\">Used valid era(s): renaissance</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_correctness:</span> <span class=\"component-value component-value-negative\">0.0</span></div><div class=\"component-reason\">Incorrect era: Expected 'modern'</div></div><div class=\"reward-component\"><div><span class=\"component-name\">date_correctness:</span> <span class=\"component-value component-value-negative\">-5.0</span></div><div class=\"component-reason\">Incorrect date: 1500 (more than 100 years from 1940)</div></div></div></div><div style=\"margin-bottom: 15px;\"><div><strong>Success Criteria:</strong></div><ul style=\"margin-top: 5px; padding-left: 20px;\"><li><span class=\"check-success\">✓ Format perfect</span></li><li><span class=\"check-fail\">❌ Era correct</span></li><li><span class=\"check-fail\">❌ Date correct</span></li></ul></div><div style=\"margin-top: 15px; padding-top: 10px; border-top: 1px solid #C4C7AC;\"><div><strong>Total Reward:</strong> <span class=\"score-high\">30.0</span></div><div><strong>Success:</strong> <span class=\"score-low\">0.0</span></div></div></div></div></div><div class=\"response-container\"><div class=\"response-header\"><div>Response #2</div><div class=\"failure-badge\">FAIL</div></div><div class=\"response-body\"> <span class=\"think-tag\">&lt;think&gt;</span> The text discusses privateers from different countries, such as French, Dutch, and English, who were active in the early 16th century. It mentions specific examples of their activities and the impact on Spanish interests. The text also mentions the Spanish response to these threats, including the establishment of armed convoys and the deployment of fleets to protect Spanish territories. This suggests that the historical era of the text is the Renaissance or the early Modern period, specifically the 16th century, when European powers were engaged in naval warfare and trade. The mention of Columbus&#x27;s voyage and the fear of French corsairs also indicates that the text is referring to a time of heightened tensions between European powers, which is characteristic of the Renaissance. Therefore, based on the content and historical context, this text appears to be from the Renaissance era, approximately in the early 16th century.<span class=\"think-tag\">&lt;/think&gt;</span> <span class=\"answer-date-tag\">&lt;answer_date&gt;</span>1520<span class=\"answer-date-tag\">&lt;/answer_date&gt;</span> <span class=\"answer-era-tag\">&lt;answer_era&gt;</span>renaissance<span class=\"answer-era-tag\">&lt;/answer_era&gt;</span></div><div class=\"metrics-container\"><div><strong class=\"metric-label\">Reward:</strong> <span class=\"metric-score score-medium\">30.0</span></div><div><strong class=\"metric-label\">Advantage:</strong> <span class=\"metric-score score-low\">0.0</span></div><a id=\"toggle-0-1\" class=\"metrics-toggle\" onclick=\"toggleDetails(0, 1)\">Show Details</a><div id=\"details-0-1\" class=\"details-container\"><div style=\"margin-bottom: 15px;\"><div><strong>Ground Truth:</strong> Era='modern', Date='1940'</div></div><div style=\"margin-bottom: 15px;\"><div><strong>Extracted Tags:</strong></div><ul style=\"margin-top: 5px; padding-left: 20px;\"><li>Think: 1 tag(s)</li><li>Era: 1 tag(s)</li><li>Date: 1 tag(s)</li></ul></div><div style=\"margin-bottom: 15px;\"><div><strong>Format Analysis:</strong></div><div class=\"check-success\">✓ No text outside tags</div></div><div style=\"margin-bottom: 15px;\"><div><strong>Content Analysis:</strong></div><div style=\"margin-top: 5px;\"><strong>Era provided:</strong> 'renaissance'</div><div><strong>Era match:</strong> <span class=\"check-fail\">❌ No match</span></div><div style=\"margin-top: 5px;\"><strong>Date provided:</strong> '1520'</div><div><strong>Best date:</strong> 1520 <span style=\"check-fail\">(diff: 420 years)</span></div></div><div style=\"margin-bottom: 15px;\"><div><strong>Reward Components:</strong></div><div style=\"margin-top: 10px;\"><div class=\"reward-component\"><div><span class=\"component-name\">think_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <think> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <answer_era> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">date_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <answer_date> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_validation:</span> <span class=\"component-value component-value-positive\">5.0</span></div><div class=\"component-reason\">Used valid era(s): renaissance</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_correctness:</span> <span class=\"component-value component-value-negative\">0.0</span></div><div class=\"component-reason\">Incorrect era: Expected 'modern'</div></div><div class=\"reward-component\"><div><span class=\"component-name\">date_correctness:</span> <span class=\"component-value component-value-negative\">-5.0</span></div><div class=\"component-reason\">Incorrect date: 1520 (more than 100 years from 1940)</div></div></div></div><div style=\"margin-bottom: 15px;\"><div><strong>Success Criteria:</strong></div><ul style=\"margin-top: 5px; padding-left: 20px;\"><li><span class=\"check-success\">✓ Format perfect</span></li><li><span class=\"check-fail\">❌ Era correct</span></li><li><span class=\"check-fail\">❌ Date correct</span></li></ul></div><div style=\"margin-top: 15px; padding-top: 10px; border-top: 1px solid #C4C7AC;\"><div><strong>Total Reward:</strong> <span class=\"score-high\">30.0</span></div><div><strong>Success:</strong> <span class=\"score-low\">0.0</span></div></div></div></div></div><div class=\"batch-header\">Batch #2</div><div class=\"response-container\"><div class=\"response-header\"><div>Response #1</div><div class=\"failure-badge\">FAIL</div></div><div class=\"response-body\"> <span class=\"think-tag\">&lt;think&gt;</span>This passage exhibits a sense of intense emotional and obsessive behavior, particularly with the protagonist&#x27;s eagerness to plan triumphs over others, his reluctance to accept any indication of indifference, and his desire to be declared beyond the power of retracting. This level of emotional investment and perceived slight suggests an era characterized by romantic and idealistic tendencies. The protagonist&#x27;s language and behavior also indicate a sense of societal pressure and social expectations, typical of the Romantic era. Furthermore, the protagonist&#x27;s reaction to the letter, describing a strong emotional response and a sense of pride and triumph, aligns with the romantic ideal of passionate and intense emotions. Therefore, based on the protagonist&#x27;s emotional state, language, and behavior, this text appears to be from the Romantic era.<span class=\"think-tag\">&lt;/think&gt;</span> <span class=\"answer-date-tag\">&lt;answer_date&gt;</span>1790<span class=\"answer-date-tag\">&lt;/answer_date&gt;</span> <span class=\"answer-era-tag\">&lt;answer_era&gt;</span>romantic<span class=\"answer-era-tag\">&lt;/answer_era&gt;</span></div><div class=\"metrics-container\"><div><strong class=\"metric-label\">Reward:</strong> <span class=\"metric-score score-low\">20.0</span></div><div><strong class=\"metric-label\">Advantage:</strong> <span class=\"metric-score score-low\">-0.7</span></div><a id=\"toggle-1-0\" class=\"metrics-toggle\" onclick=\"toggleDetails(1, 0)\">Show Details</a><div id=\"details-1-0\" class=\"details-container\"><div style=\"margin-bottom: 15px;\"><div><strong>Ground Truth:</strong> Era='modern', Date='1940'</div></div><div style=\"margin-bottom: 15px;\"><div><strong>Extracted Tags:</strong></div><ul style=\"margin-top: 5px; padding-left: 20px;\"><li>Think: 1 tag(s)</li><li>Era: 1 tag(s)</li><li>Date: 1 tag(s)</li></ul></div><div style=\"margin-bottom: 15px;\"><div><strong>Format Analysis:</strong></div><div class=\"check-success\">✓ No text outside tags</div></div><div style=\"margin-bottom: 15px;\"><div><strong>Content Analysis:</strong></div><div style=\"margin-top: 5px;\"><strong>Era provided:</strong> 'romantic'</div><div><strong>Era match:</strong> <span class=\"check-fail\">❌ No match</span></div><div style=\"margin-top: 5px;\"><strong>Date provided:</strong> '1790'</div><div><strong>Best date:</strong> 1790 <span style=\"check-fail\">(diff: 150 years)</span></div></div><div style=\"margin-bottom: 15px;\"><div><strong>Reward Components:</strong></div><div style=\"margin-top: 10px;\"><div class=\"reward-component\"><div><span class=\"component-name\">think_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <think> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <answer_era> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">date_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <answer_date> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_validation:</span> <span class=\"component-value component-value-negative\">-5.0</span></div><div class=\"component-reason\">Invalid era(s): romantic</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_correctness:</span> <span class=\"component-value component-value-negative\">0.0</span></div><div class=\"component-reason\">Incorrect era: Expected 'modern'</div></div><div class=\"reward-component\"><div><span class=\"component-name\">date_correctness:</span> <span class=\"component-value component-value-negative\">-5.0</span></div><div class=\"component-reason\">Incorrect date: 1790 (more than 100 years from 1940)</div></div></div></div><div style=\"margin-bottom: 15px;\"><div><strong>Success Criteria:</strong></div><ul style=\"margin-top: 5px; padding-left: 20px;\"><li><span class=\"check-success\">✓ Format perfect</span></li><li><span class=\"check-fail\">❌ Era correct</span></li><li><span class=\"check-fail\">❌ Date correct</span></li></ul></div><div style=\"margin-top: 15px; padding-top: 10px; border-top: 1px solid #C4C7AC;\"><div><strong>Total Reward:</strong> <span class=\"score-high\">20.0</span></div><div><strong>Success:</strong> <span class=\"score-low\">0.0</span></div></div></div></div></div><div class=\"response-container\"><div class=\"response-header\"><div>Response #2</div><div class=\"failure-badge\">FAIL</div></div><div class=\"response-body\"> <span class=\"think-tag\">&lt;think&gt;</span> I notice that the speaker is highly enthusiastic about the prospect of meeting the mysterious &quot;Narcissa&quot; and is deeply invested in the idea of triumphing over the world&#x27;s malice and contempt. The language used is overly dramatic and obsessive, characteristic of Romantic-era literature. The speaker&#x27;s emotions are intense and all-consuming, which is typical of the Romantic movement&#x27;s focus on individual emotions and experiences. Furthermore, the speaker&#x27;s pride and sense of self-importance are on full display, which is also consistent with the Romantic era&#x27;s emphasis on individualism and personal expression. Therefore, based on the emotional intensity and language used, this text appears to be from the Romantic era, specifically the late 18th century or early 19th century.<span class=\"think-tag\">&lt;/think&gt;</span> <span class=\"answer-date-tag\">&lt;answer_date&gt;</span>1790<span class=\"answer-date-tag\">&lt;/answer_date&gt;</span> <span class=\"answer-era-tag\">&lt;answer_era&gt;</span>renaissance<span class=\"answer-era-tag\">&lt;/answer_era&gt;</span></div><div class=\"metrics-container\"><div><strong class=\"metric-label\">Reward:</strong> <span class=\"metric-score score-medium\">30.0</span></div><div><strong class=\"metric-label\">Advantage:</strong> <span class=\"metric-score score-high\">0.7</span></div><a id=\"toggle-1-1\" class=\"metrics-toggle\" onclick=\"toggleDetails(1, 1)\">Show Details</a><div id=\"details-1-1\" class=\"details-container\"><div style=\"margin-bottom: 15px;\"><div><strong>Ground Truth:</strong> Era='modern', Date='1940'</div></div><div style=\"margin-bottom: 15px;\"><div><strong>Extracted Tags:</strong></div><ul style=\"margin-top: 5px; padding-left: 20px;\"><li>Think: 1 tag(s)</li><li>Era: 1 tag(s)</li><li>Date: 1 tag(s)</li></ul></div><div style=\"margin-bottom: 15px;\"><div><strong>Format Analysis:</strong></div><div class=\"check-success\">✓ No text outside tags</div></div><div style=\"margin-bottom: 15px;\"><div><strong>Content Analysis:</strong></div><div style=\"margin-top: 5px;\"><strong>Era provided:</strong> 'renaissance'</div><div><strong>Era match:</strong> <span class=\"check-fail\">❌ No match</span></div><div style=\"margin-top: 5px;\"><strong>Date provided:</strong> '1790'</div><div><strong>Best date:</strong> 1790 <span style=\"check-fail\">(diff: 150 years)</span></div></div><div style=\"margin-bottom: 15px;\"><div><strong>Reward Components:</strong></div><div style=\"margin-top: 10px;\"><div class=\"reward-component\"><div><span class=\"component-name\">think_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <think> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <answer_era> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">date_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <answer_date> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_validation:</span> <span class=\"component-value component-value-positive\">5.0</span></div><div class=\"component-reason\">Used valid era(s): renaissance</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_correctness:</span> <span class=\"component-value component-value-negative\">0.0</span></div><div class=\"component-reason\">Incorrect era: Expected 'modern'</div></div><div class=\"reward-component\"><div><span class=\"component-name\">date_correctness:</span> <span class=\"component-value component-value-negative\">-5.0</span></div><div class=\"component-reason\">Incorrect date: 1790 (more than 100 years from 1940)</div></div></div></div><div style=\"margin-bottom: 15px;\"><div><strong>Success Criteria:</strong></div><ul style=\"margin-top: 5px; padding-left: 20px;\"><li><span class=\"check-success\">✓ Format perfect</span></li><li><span class=\"check-fail\">❌ Era correct</span></li><li><span class=\"check-fail\">❌ Date correct</span></li></ul></div><div style=\"margin-top: 15px; padding-top: 10px; border-top: 1px solid #C4C7AC;\"><div><strong>Total Reward:</strong> <span class=\"score-high\">30.0</span></div><div><strong>Success:</strong> <span class=\"score-low\">0.0</span></div></div></div></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\n",
    "    rs.display_responses(\n",
    "        responses,\n",
    "        tokenizer, \n",
    "        grpo_size, \n",
    "        advantages=advantages, \n",
    "        rewards=rewards, \n",
    "        successes=successes,\n",
    "        details=details # OPTIONAL\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
