{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-22 22:50:32 __init__.py:190] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from viz import display_prompt, display_responses\n",
    "from load_torchtune_ds import load_gutenberg_dataset\n",
    "\n",
    "from vllm import LLM, SamplingParams\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtune.dev.grpo.data import padded_collate_rl\n",
    "from torchtune import config\n",
    "from torchtune.config._utils import _get_component_from_path\n",
    "\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 1\n",
    "rank = 1\n",
    "batch_size = 2\n",
    "grpo_size = 2\n",
    "\n",
    "### NOTE: this is what we are replacing.\n",
    "# cfg_dataset = DictConfig({\n",
    "#     '_component_': 'torchtune.dev.grpo.gsm8k.gsm8k_dataset',\n",
    "#     'partition': '3-5/100' \n",
    "# })\n",
    "\n",
    "root_path = os.path.expanduser('~/dev/nebius-experiments/projects/torchtune/trained_models/')\n",
    "\n",
    "cfg_tokenizer = DictConfig({\n",
    "    '_component_': 'torchtune.models.llama3.llama3_tokenizer',\n",
    "    'path': os.path.join(root_path, 'Llama3_3_70B_GRPOd_gsm8k_default_reward/original/tokenizer.model'),\n",
    "    'max_seq_len': 'null'\n",
    "})\n",
    "collate_fn = 'torchtune.dev.grpo.data.padded_collate_rl'\n",
    "\n",
    "tokenizer = config.instantiate(cfg_tokenizer)\n",
    "collate_fn = _get_component_from_path(collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 144 passages from 144 files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a69a91c9f754da08b259620c673197d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/144 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the dataset for historical context reasoning\n",
    "data_path = os.path.join(os.getcwd(), \"gutenberg_dataset\")\n",
    "if not os.path.exists(data_path):\n",
    "    raise ValueError(\"Did you run the download.py script?\")\n",
    "\n",
    "dataset = load_gutenberg_dataset(tokenizer, data_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda batch: padded_collate_rl(\n",
    "        batch,\n",
    "        padding_idx=tokenizer.pad_id,\n",
    "        ignore_idx=-100,  # CROSS_ENTROPY_IGNORE_IDX\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': tensor([[128000,     32,  21765,  ..., 128004, 128004, 128004],\n",
       "         [128000,     32,  21765,  ...,  22103,     25,    220]]),\n",
       " 'answers': ['renaissance (1575)', 'enlightenment (1725)']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(dataloader._get_iterator())\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(dataloader._get_iterator())\n",
    "tokens = batch[\"tokens\"]         # tokenized prompts\n",
    "answers = batch[\"answers\"]       # untokenized answers\n",
    "tokens = tokens                  # [batch_size x num_tokens_per_prompt]\n",
    "tokens_ls = tokens.tolist()\n",
    "out = []\n",
    "_prompts = []\n",
    "_answers = []\n",
    "for i in range(tokens.shape[0]):\n",
    "    prompt = tokenizer.decode(tokens_ls[i])\n",
    "    _prompts.extend([prompt] * grpo_size) \n",
    "    answer = answers[i]\n",
    "    _answers.extend([answer] * grpo_size)\n",
    "    # display(HTML(display_prompt(\n",
    "    #     prompt, \n",
    "    #     answer, \n",
    "    #     tokenizer\n",
    "    # )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing rewards_v0.py\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%%writefile rewards_v0.py\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "from typing import Tuple, List, Dict, Any, Optional\n",
    "import torch\n",
    "import re\n",
    "from torchtune.modules.transforms.tokenizers import ModelTokenizer\n",
    "\n",
    "# Define valid eras for validation\n",
    "VALID_ERAS = [\n",
    "    \"renaissance\",\n",
    "    \"enlightenment\",\n",
    "    \"victorian\",\n",
    "    \"edwardian\",\n",
    "    \"modern\"\n",
    "]\n",
    "\n",
    "def check_outside_text(text: str) -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    More robust function to detect text outside the required tags.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to analyze\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (has_outside_text, outside_text)\n",
    "    \"\"\"\n",
    "    # First strip whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Use regex to extract all tag content\n",
    "    pattern = r\"<(think|answer_date|answer_era)>(.*?)</\\1>\"\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    # Create a cleaned version for comparison\n",
    "    cleaned_text = text\n",
    "    \n",
    "    # Remove all valid tag content\n",
    "    for tag, content in matches:\n",
    "        cleaned_text = cleaned_text.replace(f\"<{tag}>{content}</{tag}>\", \"\", 1)\n",
    "    \n",
    "    # Strip whitespace again\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    \n",
    "    return bool(cleaned_text), cleaned_text\n",
    "\n",
    "\n",
    "def extract_tags(text: str) -> dict[str, list[str]]:\n",
    "    \"\"\"\n",
    "    Parse XML-like tags from text, with improved handling for malformed XML.\n",
    "    \n",
    "    Args:\n",
    "        text: Text potentially containing XML tags\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with tag content keyed by tag name\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"think\": [],\n",
    "        \"answer_era\": [],\n",
    "        \"answer_date\": []\n",
    "    }\n",
    "    \n",
    "    # First, try regex method (more robust for malformed XML)\n",
    "    for tag in [\"think\", \"answer_era\", \"answer_date\"]:\n",
    "        pattern = f\"<{tag}>(.*?)</{tag}>\"\n",
    "        matches = re.findall(pattern, text, re.DOTALL)\n",
    "        if matches:\n",
    "            # Trim whitespace from each match\n",
    "            results[tag] = [match.strip() for match in matches]\n",
    "    \n",
    "    # If regex found matches, return those\n",
    "    if any(len(v) > 0 for v in results.values()):\n",
    "        return results\n",
    "    \n",
    "    # Otherwise try the XML parser as fallback\n",
    "    xml_string = f\"<root>{text}</root>\"\n",
    "    try:\n",
    "        root = ET.fromstring(xml_string)\n",
    "        for tag in [\"think\", \"answer_era\", \"answer_date\"]:\n",
    "            results[tag] = [\n",
    "                (elem.text.strip() if elem.text else \"\") \n",
    "                for elem in root.findall(tag)\n",
    "            ]\n",
    "        return results\n",
    "    except ET.ParseError:\n",
    "        # Return the empty results if both methods fail\n",
    "        return results\n",
    "\n",
    "\n",
    "def shaped_correctness_reward(answer: str, completion: str) -> tuple[float, float, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Enhanced reward function for historical era identification with detailed diagnostics.\n",
    "    \n",
    "    Args:\n",
    "        answer: Ground-truth answer string in format \"era (date)\"\n",
    "        completion: Model's completion string\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (reward_score, success_flag, details_dict)\n",
    "    \"\"\"\n",
    "    reward = 0.0\n",
    "    success = 0.0\n",
    "    \n",
    "    # Create details dictionary for diagnostics\n",
    "    details = {\n",
    "        \"ground_truth\": {\n",
    "            \"original\": answer,\n",
    "            \"era\": \"\",\n",
    "            \"date\": \"\"\n",
    "        },\n",
    "        \"completion\": completion[:100] + (\"...\" if len(completion) > 100 else \"\"),  # Truncated for readability\n",
    "        \"extracted_tags\": {},\n",
    "        \"format_analysis\": {},\n",
    "        \"content_analysis\": {},\n",
    "        \"reward_components\": [],\n",
    "        \"total_reward\": 0.0,\n",
    "        \"success\": 0.0\n",
    "    }\n",
    "    \n",
    "    # Parse the ground truth era and date\n",
    "    gt_match = re.match(r'([a-z]+)\\s*\\((\\d+)\\)', answer.lower())\n",
    "    if gt_match:\n",
    "        gt_era = gt_match.group(1).strip()\n",
    "        gt_date = gt_match.group(2).strip()\n",
    "    else:\n",
    "        # Fallback if parsing fails\n",
    "        gt_era = answer.lower().strip()\n",
    "        gt_date = \"\"\n",
    "    \n",
    "    # Store ground truth values in details\n",
    "    details[\"ground_truth\"][\"era\"] = gt_era\n",
    "    details[\"ground_truth\"][\"date\"] = gt_date\n",
    "    \n",
    "    # Extract tags from completion\n",
    "    tags = extract_tags(completion)\n",
    "    details[\"extracted_tags\"] = {\n",
    "        \"think\": tags[\"think\"],\n",
    "        \"answer_era\": tags[\"answer_era\"],\n",
    "        \"answer_date\": tags[\"answer_date\"]\n",
    "    }\n",
    "    \n",
    "    # Check for text outside tags - improved method\n",
    "    has_outside_text, outside_text = check_outside_text(completion)\n",
    "    details[\"format_analysis\"][\"has_outside_text\"] = has_outside_text\n",
    "    if has_outside_text:\n",
    "        details[\"format_analysis\"][\"outside_text\"] = outside_text[:100] + (\"...\" if len(outside_text) > 100 else \"\")\n",
    "    \n",
    "    # Apply significant penalties for text outside tags\n",
    "    if has_outside_text:\n",
    "        # More aggressive penalty for text outside tags\n",
    "        penalty = min(30.0, len(outside_text) * 0.2)\n",
    "        reward -= penalty\n",
    "        details[\"reward_components\"].append({\n",
    "            \"component\": \"outside_text_penalty\",\n",
    "            \"value\": -penalty,\n",
    "            \"reason\": f\"Text found outside required tags: '{outside_text[:30]}...' ({len(outside_text)} chars)\"\n",
    "        })\n",
    "    \n",
    "    # Format rewards - higher values for proper formatting\n",
    "    if len(tags[\"think\"]) == 1:\n",
    "        reward += 10.0  # Good reward for having exactly one thinking section\n",
    "        details[\"reward_components\"].append({\n",
    "            \"component\": \"think_tag_format\",\n",
    "            \"value\": 10.0,\n",
    "            \"reason\": \"Correct: Exactly one <think> tag\"\n",
    "        })\n",
    "    elif len(tags[\"think\"]) > 1:\n",
    "        reward += 2.5   # Smaller reward for having thinking, but too many sections\n",
    "        details[\"reward_components\"].append({\n",
    "            \"component\": \"think_tag_format\",\n",
    "            \"value\": 2.5,\n",
    "            \"reason\": f\"Partial: {len(tags['think'])} <think> tags found (expected 1)\"\n",
    "        })\n",
    "    else:\n",
    "        reward -= 5.0   # Penalty for missing thinking section\n",
    "        details[\"reward_components\"].append({\n",
    "            \"component\": \"think_tag_format\",\n",
    "            \"value\": -5.0,\n",
    "            \"reason\": \"Missing <think> tag\"\n",
    "        })\n",
    "    \n",
    "    if len(tags[\"answer_era\"]) == 1:\n",
    "        reward += 10.0  # Increased reward for having exactly one era tag\n",
    "        details[\"reward_components\"].append({\n",
    "            \"component\": \"era_tag_format\",\n",
    "            \"value\": 10.0,\n",
    "            \"reason\": \"Correct: Exactly one <answer_era> tag\"\n",
    "        })\n",
    "    elif len(tags[\"answer_era\"]) > 1:\n",
    "        reward += 2.5   # Some reward for having era tags, but too many\n",
    "        details[\"reward_components\"].append({\n",
    "            \"component\": \"era_tag_format\",\n",
    "            \"value\": 2.5,\n",
    "            \"reason\": f\"Partial: {len(tags['answer_era'])} <answer_era> tags found (expected 1)\"\n",
    "        })\n",
    "    else:\n",
    "        reward -= 10.0  # Stronger penalty for missing era\n",
    "        details[\"reward_components\"].append({\n",
    "            \"component\": \"era_tag_format\",\n",
    "            \"value\": -10.0,\n",
    "            \"reason\": \"Missing <answer_era> tag\"\n",
    "        })\n",
    "    \n",
    "    if len(tags[\"answer_date\"]) == 1:\n",
    "        reward += 10.0  # Increased reward for having exactly one date tag\n",
    "        details[\"reward_components\"].append({\n",
    "            \"component\": \"date_tag_format\",\n",
    "            \"value\": 10.0,\n",
    "            \"reason\": \"Correct: Exactly one <answer_date> tag\"\n",
    "        })\n",
    "    elif len(tags[\"answer_date\"]) > 1:\n",
    "        reward += 2.5   # Some reward for having date tags, but too many\n",
    "        details[\"reward_components\"].append({\n",
    "            \"component\": \"date_tag_format\",\n",
    "            \"value\": 2.5,\n",
    "            \"reason\": f\"Partial: {len(tags['answer_date'])} <answer_date> tags found (expected 1)\"\n",
    "        })\n",
    "    else:\n",
    "        reward -= 10.0  # Stronger penalty for missing date\n",
    "        details[\"reward_components\"].append({\n",
    "            \"component\": \"date_tag_format\",\n",
    "            \"value\": -10.0,\n",
    "            \"reason\": \"Missing <answer_date> tag\"\n",
    "        })\n",
    "        \n",
    "    # Era validation rewards\n",
    "    if tags[\"answer_era\"]:\n",
    "        # Store era analysis\n",
    "        details[\"content_analysis\"][\"era\"] = {\n",
    "            \"provided\": [era.lower() for era in tags[\"answer_era\"]],\n",
    "            \"valid_eras\": VALID_ERAS,\n",
    "            \"ground_truth\": gt_era\n",
    "        }\n",
    "        \n",
    "        # Check if any provided era is in the valid list\n",
    "        valid_provided = [era.lower() for era in tags[\"answer_era\"] if era.lower() in VALID_ERAS]\n",
    "        if valid_provided:\n",
    "            reward += 5.0  # Bonus for using a valid era from the list\n",
    "            details[\"reward_components\"].append({\n",
    "                \"component\": \"era_validation\",\n",
    "                \"value\": 5.0,\n",
    "                \"reason\": f\"Used valid era(s): {', '.join(valid_provided)}\"\n",
    "            })\n",
    "        else:\n",
    "            reward -= 5.0  # Penalty for using invalid era\n",
    "            details[\"reward_components\"].append({\n",
    "                \"component\": \"era_validation\",\n",
    "                \"value\": -5.0,\n",
    "                \"reason\": f\"Invalid era(s): {', '.join([era.lower() for era in tags['answer_era']])}\"\n",
    "            })\n",
    "    \n",
    "    # Correctness rewards for era\n",
    "    if tags[\"answer_era\"]:\n",
    "        exact_match = any(gt_era == attempt.lower().strip() for attempt in tags[\"answer_era\"])\n",
    "        partial_match = any(gt_era in attempt.lower().strip() for attempt in tags[\"answer_era\"])\n",
    "        \n",
    "        details[\"content_analysis\"][\"era_match\"] = {\n",
    "            \"exact_match\": exact_match,\n",
    "            \"partial_match\": partial_match\n",
    "        }\n",
    "        \n",
    "        if exact_match:\n",
    "            # One of the answer_era tags has the exact right era\n",
    "            reward += 30.0  # Increased reward for correct era\n",
    "            details[\"reward_components\"].append({\n",
    "                \"component\": \"era_correctness\",\n",
    "                \"value\": 30.0,\n",
    "                \"reason\": f\"Correct era: {gt_era}\"\n",
    "            })\n",
    "        elif partial_match:\n",
    "            # One of the answer_era tags contains the right era as a substring\n",
    "            reward += 10.0  # Partial reward\n",
    "            details[\"reward_components\"].append({\n",
    "                \"component\": \"era_correctness\",\n",
    "                \"value\": 10.0,\n",
    "                \"reason\": f\"Partial era match: Contains '{gt_era}'\"\n",
    "            })\n",
    "        else:\n",
    "            details[\"reward_components\"].append({\n",
    "                \"component\": \"era_correctness\",\n",
    "                \"value\": 0.0,\n",
    "                \"reason\": f\"Incorrect era: Expected '{gt_era}'\"\n",
    "            })\n",
    "    \n",
    "    # Correctness rewards for date\n",
    "    if gt_date and tags[\"answer_date\"]:\n",
    "        try:\n",
    "            gt_year = int(gt_date)\n",
    "            \n",
    "            # Parse all dates and track errors\n",
    "            date_attempts = []\n",
    "            valid_dates = []\n",
    "            \n",
    "            for attempt in tags[\"answer_date\"]:\n",
    "                attempt = attempt.strip()\n",
    "                date_attempts.append(attempt)\n",
    "                if attempt.isdigit():\n",
    "                    valid_dates.append(int(attempt))\n",
    "            \n",
    "            details[\"content_analysis\"][\"date\"] = {\n",
    "                \"provided\": date_attempts,\n",
    "                \"valid_dates\": valid_dates,\n",
    "                \"ground_truth\": gt_year\n",
    "            }\n",
    "            \n",
    "            if valid_dates:\n",
    "                # Find best date attempt (closest to ground truth)\n",
    "                best_diff = min(abs(date - gt_year) for date in valid_dates)\n",
    "                best_date = next(date for date in valid_dates if abs(date - gt_year) == best_diff)\n",
    "                \n",
    "                details[\"content_analysis\"][\"date\"][\"best_match\"] = {\n",
    "                    \"value\": best_date,\n",
    "                    \"difference\": best_diff\n",
    "                }\n",
    "                \n",
    "                # Award based on closest date\n",
    "                if best_diff == 0:\n",
    "                    # Exact date match\n",
    "                    reward += 30.0  # Increased reward\n",
    "                    details[\"reward_components\"].append({\n",
    "                        \"component\": \"date_correctness\",\n",
    "                        \"value\": 30.0,\n",
    "                        \"reason\": f\"Exact date match: {best_date}\"\n",
    "                    })\n",
    "                elif best_diff <= 20:\n",
    "                    # Within 20 years\n",
    "                    reward += 20.0  # Increased reward\n",
    "                    details[\"reward_components\"].append({\n",
    "                        \"component\": \"date_correctness\",\n",
    "                        \"value\": 20.0,\n",
    "                        \"reason\": f\"Close date match: {best_date} (within 20 years of {gt_year})\"\n",
    "                    })\n",
    "                elif best_diff <= 50:\n",
    "                    # Within 50 years\n",
    "                    reward += 10.0\n",
    "                    details[\"reward_components\"].append({\n",
    "                        \"component\": \"date_correctness\",\n",
    "                        \"value\": 10.0,\n",
    "                        \"reason\": f\"Approximate date: {best_date} (within 50 years of {gt_year})\"\n",
    "                    })\n",
    "                elif best_diff <= 100:\n",
    "                    # Within 100 years\n",
    "                    reward += 5.0\n",
    "                    details[\"reward_components\"].append({\n",
    "                        \"component\": \"date_correctness\",\n",
    "                        \"value\": 5.0,\n",
    "                        \"reason\": f\"Distant date: {best_date} (within 100 years of {gt_year})\"\n",
    "                    })\n",
    "                else:\n",
    "                    # More than 100 years off\n",
    "                    reward -= 5.0  # Small penalty for very wrong date\n",
    "                    details[\"reward_components\"].append({\n",
    "                        \"component\": \"date_correctness\",\n",
    "                        \"value\": -5.0,\n",
    "                        \"reason\": f\"Incorrect date: {best_date} (more than 100 years from {gt_year})\"\n",
    "                    })\n",
    "            else:\n",
    "                # No valid numeric dates found\n",
    "                reward -= 5.0  # Penalty for non-numeric date\n",
    "                details[\"reward_components\"].append({\n",
    "                    \"component\": \"date_correctness\",\n",
    "                    \"value\": -5.0,\n",
    "                    \"reason\": f\"Non-numeric date(s): {', '.join(date_attempts)}\"\n",
    "                })\n",
    "                \n",
    "        except ValueError as e:\n",
    "            # Penalty for non-numeric date\n",
    "            reward -= 5.0\n",
    "            details[\"reward_components\"].append({\n",
    "                \"component\": \"date_correctness\",\n",
    "                \"value\": -5.0,\n",
    "                \"reason\": f\"Date parsing error: {str(e)}\"\n",
    "            })\n",
    "    \n",
    "    # Full success criteria - more strict\n",
    "    # Both era and date must be correct AND format must be perfect\n",
    "    perfect_format = (\n",
    "        len(tags[\"think\"]) == 1 and \n",
    "        len(tags[\"answer_era\"]) == 1 and \n",
    "        len(tags[\"answer_date\"]) == 1 and\n",
    "        not has_outside_text\n",
    "    )\n",
    "    \n",
    "    correct_era = (\n",
    "        tags[\"answer_era\"] and \n",
    "        tags[\"answer_era\"][0].lower().strip() == gt_era\n",
    "    )\n",
    "    \n",
    "    correct_date = (\n",
    "        gt_date and\n",
    "        tags[\"answer_date\"] and\n",
    "        tags[\"answer_date\"][0].isdigit() and \n",
    "        abs(int(tags[\"answer_date\"][0]) - int(gt_date)) <= 20\n",
    "    )\n",
    "    \n",
    "    details[\"success_criteria\"] = {\n",
    "        \"perfect_format\": perfect_format,\n",
    "        \"correct_era\": correct_era,\n",
    "        \"correct_date\": correct_date\n",
    "    }\n",
    "    \n",
    "    if perfect_format and correct_era and correct_date:\n",
    "        reward = 100.0\n",
    "        success = 1.0\n",
    "        details[\"reward_components\"].append({\n",
    "            \"component\": \"perfect_answer\",\n",
    "            \"value\": \"100.0 (overwrites previous)\",\n",
    "            \"reason\": \"Perfect format and correct answers\"\n",
    "        })\n",
    "    \n",
    "    # Store final reward and success in details\n",
    "    details[\"total_reward\"] = reward\n",
    "    details[\"success\"] = success\n",
    "    \n",
    "    return reward, success, details\n",
    "\n",
    "\n",
    "def batch_shaped_correctness_reward(\n",
    "    tokenizer: ModelTokenizer, \n",
    "    completions: torch.Tensor, \n",
    "    answers: List[str],\n",
    "    details_report: bool = False\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, Optional[List[Dict[str, Any]]]]:\n",
    "    \"\"\"\n",
    "    Apply the shaped reward function to a batch of completions.\n",
    "    \n",
    "    Args:\n",
    "        tokenizer: Tokenizer for decoding completions\n",
    "        completions: Tensor of token IDs\n",
    "        answers: List of ground truth answers\n",
    "        details_report: Whether to generate detailed diagnostic reports\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (rewards, successes, optional details list)\n",
    "    \"\"\"\n",
    "    batch_size, grpo_size, *_ = completions.shape\n",
    "    rewards = torch.zeros(batch_size, grpo_size, dtype=torch.float32)\n",
    "    successes = torch.zeros(batch_size, grpo_size, dtype=torch.float32)\n",
    "    \n",
    "    # Create container for details if requested\n",
    "    details_list = [] if details_report else None\n",
    "    \n",
    "    # Process each completion in the batch\n",
    "    for b in range(batch_size):\n",
    "        batch_details = [] if details_report else None\n",
    "        \n",
    "        for g in range(grpo_size):\n",
    "            # Decode the completion\n",
    "            text_completion = tokenizer.decode(\n",
    "                completions[b, g].tolist()\n",
    "            )\n",
    "            \n",
    "            # Calculate reward, success, and details\n",
    "            reward, success, details = shaped_correctness_reward(\n",
    "                answer=answers[b], \n",
    "                completion=text_completion\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            rewards[b, g] = reward\n",
    "            successes[b, g] = success\n",
    "            \n",
    "            # Store details if requested\n",
    "            if details_report:\n",
    "                # Add batch and group indices\n",
    "                details[\"batch_idx\"] = b\n",
    "                details[\"group_idx\"] = g\n",
    "                batch_details.append(details)\n",
    "        \n",
    "        # Add batch details to the main list\n",
    "        if details_report:\n",
    "            details_list.append(batch_details)\n",
    "    \n",
    "    return rewards, successes, details_list\n",
    "\n",
    "\n",
    "# Helper function to print a readable summary of the details\n",
    "def print_reward_details_summary(details: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Print a human-readable summary of the reward details.\n",
    "    \n",
    "    Args:\n",
    "        details: The details dictionary from shaped_correctness_reward\n",
    "    \"\"\"\n",
    "    print(f\"=== Reward Calculation Summary ===\")\n",
    "    print(f\"Ground Truth: Era='{details['ground_truth']['era']}', Date='{details['ground_truth']['date']}'\")\n",
    "    print(f\"Completion: {details['completion']}\")\n",
    "    print(\"\\nExtracted Tags:\")\n",
    "    print(f\"  Think: {len(details['extracted_tags']['think'])} tag(s)\")\n",
    "    print(f\"  Era: {len(details['extracted_tags']['answer_era'])} tag(s)\")\n",
    "    print(f\"  Date: {len(details['extracted_tags']['answer_date'])} tag(s)\")\n",
    "    \n",
    "    print(\"\\nFormat Analysis:\")\n",
    "    if details['format_analysis'].get('has_outside_text', False):\n",
    "        print(f\"  ❌ Text outside tags: {details['format_analysis']['outside_text']}\")\n",
    "    else:\n",
    "        print(f\"  ✓ No text outside tags\")\n",
    "    \n",
    "    print(\"\\nContent Analysis:\")\n",
    "    if 'era' in details['content_analysis']:\n",
    "        print(f\"  Era provided: {details['content_analysis']['era']['provided']}\")\n",
    "        match_status = \"❌ No match\"\n",
    "        if details['content_analysis'].get('era_match', {}).get('exact_match', False):\n",
    "            match_status = \"✓ Exact match\"\n",
    "        elif details['content_analysis'].get('era_match', {}).get('partial_match', False):\n",
    "            match_status = \"~ Partial match\"\n",
    "        print(f\"  Era match: {match_status}\")\n",
    "    \n",
    "    if 'date' in details['content_analysis']:\n",
    "        print(f\"  Date provided: {details['content_analysis']['date']['provided']}\")\n",
    "        if 'best_match' in details['content_analysis']['date']:\n",
    "            best = details['content_analysis']['date']['best_match']\n",
    "            print(f\"  Best date: {best['value']} (diff: {best['difference']} years)\")\n",
    "    \n",
    "    print(\"\\nReward Components:\")\n",
    "    for component in details['reward_components']:\n",
    "        print(f\"  {component['component']}: {component['value']} - {component['reason']}\")\n",
    "    \n",
    "    print(f\"\\nTotal Reward: {details['total_reward']}\")\n",
    "    print(f\"Success: {details['success']}\")\n",
    "    \n",
    "    if 'success_criteria' in details:\n",
    "        criteria = details['success_criteria']\n",
    "        print(\"\\nSuccess Criteria:\")\n",
    "        print(f\"  Format perfect: {'✓' if criteria['perfect_format'] else '❌'}\")\n",
    "        print(f\"  Era correct: {'✓' if criteria['correct_era'] else '❌'}\")\n",
    "        print(f\"  Date correct: {'✓' if criteria['correct_date'] else '❌'}\")\n",
    "    \n",
    "    print(\"================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 03-22 22:50:39 arg_utils.py:1135] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\n",
      "INFO 03-22 22:50:39 config.py:1556] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
      "INFO 03-22 22:50:39 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='/tmp/Llama-3.2-3B-Instruct/', speculative_config=None, tokenizer='/tmp/Llama-3.2-3B-Instruct/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/tmp/Llama-3.2-3B-Instruct/, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "INFO 03-22 22:50:40 cuda.py:230] Using Flash Attention backend.\n",
      "INFO 03-22 22:50:40 model_runner.py:1110] Starting to load model /tmp/Llama-3.2-3B-Instruct/...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d16d72b40fb480683742e0a0e91609c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-22 22:50:42 model_runner.py:1115] Loading model weights took 6.0160 GB\n",
      "INFO 03-22 22:50:43 worker.py:267] Memory profiling takes 0.65 seconds\n",
      "INFO 03-22 22:50:43 worker.py:267] the current vLLM instance can use total_gpu_memory (79.10GiB) x gpu_memory_utilization (0.90) = 71.19GiB\n",
      "INFO 03-22 22:50:43 worker.py:267] model weights take 6.02GiB; non_torch_memory takes 0.15GiB; PyTorch activation peak memory takes 1.21GiB; the rest of the memory reserved for KV Cache is 63.81GiB.\n",
      "INFO 03-22 22:50:43 executor_base.py:110] # CUDA blocks: 37339, # CPU blocks: 2340\n",
      "INFO 03-22 22:50:43 executor_base.py:115] Maximum concurrency for 131072 tokens per request: 4.56x\n",
      "INFO 03-22 22:50:45 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:09<00:00,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-22 22:50:55 model_runner.py:1562] Graph capturing finished in 10 secs, took 0.29 GiB\n",
      "INFO 03-22 22:50:55 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 13.11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = '/tmp/Llama-3.2-3B-Instruct/'\n",
    "llm = LLM(\n",
    "    model=path, \n",
    "    task=\"generate\", \n",
    "    trust_remote_code=True,\n",
    "    # tensor_parallel_size=1,\n",
    "    dtype='bfloat16'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 4/4 [00:01<00:00,  2.81it/s, est. speed input: 1795.69 toks/s, output: 620.12 toks/s]\n"
     ]
    }
   ],
   "source": [
    "sampling_params = SamplingParams(\n",
    "    temperature=0.8, \n",
    "    top_p=0.95,\n",
    "    max_tokens=512\n",
    ")\n",
    "output = llm.generate(_prompts, sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_token_ids = [\n",
    "    128001,\n",
    "    128009,\n",
    "    128008\n",
    "]\n",
    "pad_id = 128004\n",
    "max_tokens = 512\n",
    "\n",
    "data = []\n",
    "for o in output:\n",
    "    out_tokens = list(o.outputs[0].token_ids)\n",
    "    if len(out_tokens) < max_tokens:\n",
    "        out_tokens += [pad_id] * (max_tokens - len(out_tokens))\n",
    "    data.append(out_tokens)\n",
    "responses=torch.tensor(data, dtype=torch.int32).reshape(batch_size, grpo_size, max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses.shape # [batch_size, grpo_size, generation_max_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rewards_v0 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards, successes, details = batch_shaped_correctness_reward(     \n",
    "  tokenizer=tokenizer,      \n",
    "  completions=responses,      \n",
    "  answers=_answers,\n",
    "  details_report=True  # Enables detailed diagnostics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Reward Calculation Summary ===\n",
      "Ground Truth: Era='renaissance', Date='1575'\n",
      "Completion:  <think>The language and style used in this passage are reminiscent of Shakespeare's plays, particul...\n",
      "\n",
      "Extracted Tags:\n",
      "  Think: 1 tag(s)\n",
      "  Era: 1 tag(s)\n",
      "  Date: 1 tag(s)\n",
      "\n",
      "Format Analysis:\n",
      "  ✓ No text outside tags\n",
      "\n",
      "Content Analysis:\n",
      "  Era provided: ['renaissance']\n",
      "  Era match: ✓ Exact match\n",
      "  Date provided: ['1600']\n",
      "  Best date: 1600 (diff: 25 years)\n",
      "\n",
      "Reward Components:\n",
      "  think_tag_format: 10.0 - Correct: Exactly one <think> tag\n",
      "  era_tag_format: 10.0 - Correct: Exactly one <answer_era> tag\n",
      "  date_tag_format: 10.0 - Correct: Exactly one <answer_date> tag\n",
      "  era_validation: 5.0 - Used valid era(s): renaissance\n",
      "  era_correctness: 30.0 - Correct era: renaissance\n",
      "  date_correctness: 10.0 - Approximate date: 1600 (within 50 years of 1575)\n",
      "\n",
      "Total Reward: 75.0\n",
      "Success: 0.0\n",
      "\n",
      "Success Criteria:\n",
      "  Format perfect: ✓\n",
      "  Era correct: ✓\n",
      "  Date correct: ❌\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "batch_idx = 0\n",
    "group_member_idx = 0\n",
    "print_reward_details_summary(details[batch_idx][group_member_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[75., 45.],\n",
       "        [20., 30.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "advantages = (rewards - rewards.mean(1, keepdim=True)) / (\n",
    "    rewards.std(1, keepdim=True) + 1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7071, -0.7071],\n",
       "        [-0.7071,  0.7071]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "\n",
    "def display_responses(\n",
    "    responses: torch.Tensor,\n",
    "    tokenizer: ModelTokenizer,\n",
    "    grpo_size: int,\n",
    "    advantages: Optional[torch.Tensor] = None,\n",
    "    rewards: Optional[torch.Tensor] = None,\n",
    "    successes: Optional[torch.Tensor] = None,\n",
    "    details: Optional[List[List[Dict[str, Any]]]] = None,\n",
    "    show_n: Optional[int] = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Display responses with rewards, advantages, and detailed diagnostics in a visually appealing format.\n",
    "    \n",
    "    Args:\n",
    "        responses: Tensor of token IDs\n",
    "        tokenizer: Tokenizer for decoding responses\n",
    "        grpo_size: Size of the policy optimization group\n",
    "        advantages: Optional tensor of advantages\n",
    "        rewards: Optional tensor of rewards\n",
    "        successes: Optional tensor of successes\n",
    "        details: Optional list of reward calculation details\n",
    "        show_n: Optional maximum number of responses to display\n",
    "        \n",
    "    Returns:\n",
    "        HTML string for displaying the responses\n",
    "    \"\"\"\n",
    "    batch_size = responses.shape[0]\n",
    "    \n",
    "    # Helper function to safely get values from tensors with different shapes\n",
    "    def get_item_value(tensor, batch_idx, group_idx):\n",
    "        if tensor is None:\n",
    "            return None\n",
    "        \n",
    "        if tensor.dim() == 1:\n",
    "            # Handle 1D tensor [grpo_size]\n",
    "            return tensor[group_idx].item()\n",
    "        else:\n",
    "            # Handle 2D tensor [batch_size, grpo_size]\n",
    "            return tensor[batch_idx][group_idx].item()\n",
    "    \n",
    "    html_output = \"\"\"\n",
    "    <style>\n",
    "        .response-container {\n",
    "            margin: 20px 0;\n",
    "            border: 1px solid #C4C7AC;\n",
    "            border-radius: 8px;\n",
    "            overflow: hidden;\n",
    "            box-shadow: 0 2px 5px rgba(0,0,0,0.05);\n",
    "            font-family: 'Courier New', monospace;\n",
    "            max-width: 100%;\n",
    "        }\n",
    "        .response-header {\n",
    "            background-color: #F0EBE5;\n",
    "            padding: 10px 15px;\n",
    "            font-size: 16px;\n",
    "            font-weight: bold;\n",
    "            border-bottom: 1px solid #C4C7AC;\n",
    "            color: #4A4A67;\n",
    "            display: flex;\n",
    "            justify-content: space-between;\n",
    "            align-items: center;\n",
    "        }\n",
    "        .response-body {\n",
    "            background-color: #ffffff;\n",
    "            color: #4A4A67;\n",
    "            padding: 15px;\n",
    "            white-space: pre-wrap;\n",
    "            word-wrap: break-word;\n",
    "            line-height: 1.6;\n",
    "            font-size: 14px;\n",
    "        }\n",
    "        .think-tag {\n",
    "            color: #BE6A1A;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "        .answer-tag {\n",
    "            color: #2C6846;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "        .answer-era-tag {\n",
    "            color: #2C6846;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "        .answer-date-tag {\n",
    "            color: #2C6846;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "        .metrics-container {\n",
    "            background-color: #F0EBE5;\n",
    "            border-top: 1px solid #C4C7AC;\n",
    "            padding: 10px 15px;\n",
    "        }\n",
    "        .metric-label {\n",
    "            color: #4A4A67;\n",
    "        }\n",
    "        .metric-score {\n",
    "            font-family: monospace;\n",
    "            font-weight: bold;\n",
    "            padding: 2px 8px;\n",
    "            border-radius: 4px;\n",
    "            display: inline-block;\n",
    "            margin-right: 8px;\n",
    "        }\n",
    "        .score-high {\n",
    "            background-color: #D3EFE0;\n",
    "            color: #177350;\n",
    "        }\n",
    "        .score-medium {\n",
    "            background-color: #FCF1D6;\n",
    "            color: #BE6A1A;\n",
    "        }\n",
    "        .score-low {\n",
    "            background-color: #FAD9D8;\n",
    "            color: #C5393A;\n",
    "        }\n",
    "        .success-badge {\n",
    "            background-color: #177350;\n",
    "            color: white;\n",
    "            padding: 3px 8px;\n",
    "            border-radius: 4px;\n",
    "            font-size: 12px;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "        .failure-badge {\n",
    "            background-color: #C5393A;\n",
    "            color: white;\n",
    "            padding: 3px 8px;\n",
    "            border-radius: 4px;\n",
    "            font-size: 12px;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "        .metrics-toggle {\n",
    "            cursor: pointer;\n",
    "            color: #3F7DC9;\n",
    "            text-decoration: underline;\n",
    "            font-size: 12px;\n",
    "            margin-top: 5px;\n",
    "            display: inline-block;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "        .details-container {\n",
    "            display: none;\n",
    "            margin-top: 10px;\n",
    "            border-top: 1px solid #C4C7AC;\n",
    "            padding-top: 10px;\n",
    "        }\n",
    "        \n",
    "        /* Reward details styling */\n",
    "        .reward-component {\n",
    "            margin-bottom: 10px;\n",
    "            padding: 8px;\n",
    "            border-radius: 4px;\n",
    "            background-color: #f8f9fa;\n",
    "        }\n",
    "        .component-name {\n",
    "            font-weight: bold;\n",
    "            color: #4A4A67;\n",
    "        }\n",
    "        .component-value {\n",
    "            font-family: monospace;\n",
    "            padding: 2px 4px;\n",
    "            border-radius: 3px;\n",
    "        }\n",
    "        .component-value-positive {\n",
    "            background-color: #D3EFE0;\n",
    "            color: #177350;\n",
    "        }\n",
    "        .component-value-negative {\n",
    "            background-color: #FAD9D8;\n",
    "            color: #C5393A;\n",
    "        }\n",
    "        .component-reason {\n",
    "            font-size: 0.9em;\n",
    "            color: #555;\n",
    "            margin-top: 4px;\n",
    "        }\n",
    "        .check-success {\n",
    "            color: #177350;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "        .check-fail {\n",
    "            color: #C5393A;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "        .batch-header {\n",
    "            margin: 30px 0 10px 0;\n",
    "            padding: 5px 10px;\n",
    "            background-color: #E5E7D9;\n",
    "            border-left: 4px solid #4A4A67;\n",
    "            color: #4A4A67;\n",
    "            font-size: 18px;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "    </style>\n",
    "    \n",
    "    <script>\n",
    "    function toggleDetails(batchIdx, groupIdx) {\n",
    "        var detailsId = 'details-' + batchIdx + '-' + groupIdx;\n",
    "        var details = document.getElementById(detailsId);\n",
    "        var buttonId = 'toggle-' + batchIdx + '-' + groupIdx;\n",
    "        var toggleBtn = document.getElementById(buttonId);\n",
    "        \n",
    "        if (details) {\n",
    "            if (details.style.display === 'none' || details.style.display === '') {\n",
    "                details.style.display = 'block';\n",
    "                if (toggleBtn) toggleBtn.innerText = 'Hide Details';\n",
    "            } else {\n",
    "                details.style.display = 'none';\n",
    "                if (toggleBtn) toggleBtn.innerText = 'Show Details';\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    \n",
    "    if show_n is not None:\n",
    "        grpo_size = min(grpo_size, show_n)\n",
    "    \n",
    "    for b in range(batch_size):\n",
    "        html_output += f'<div class=\"batch-header\">Batch #{b+1}</div>'\n",
    "        \n",
    "        for g in range(grpo_size):\n",
    "            # Decode the response\n",
    "            response_text = tokenizer.decode(responses[b, g].tolist())\n",
    "            \n",
    "            # Determine if this response succeeded\n",
    "            success_value = get_item_value(successes, b, g) if successes is not None else None\n",
    "            is_successful = success_value == 1.0 if success_value is not None else None\n",
    "            \n",
    "            # Get reward and advantage if available\n",
    "            reward_value = get_item_value(rewards, b, g) if rewards is not None else None\n",
    "            advantage_value = get_item_value(advantages, b, g) if advantages is not None else None\n",
    "            \n",
    "            # Start response container\n",
    "            html_output += f'<div class=\"response-container\">'\n",
    "            \n",
    "            # Response header\n",
    "            html_output += f'<div class=\"response-header\">'\n",
    "            html_output += f'<div>Response #{g+1}</div>'\n",
    "            \n",
    "            # Add success/fail badge if available\n",
    "            if is_successful is not None:\n",
    "                if is_successful:\n",
    "                    html_output += f'<div class=\"success-badge\">SUCCESS</div>'\n",
    "                else:\n",
    "                    html_output += f'<div class=\"failure-badge\">FAIL</div>'\n",
    "            \n",
    "            html_output += '</div>'  # End response header\n",
    "            \n",
    "            # Response body with tag highlighting\n",
    "            html_output += f'<div class=\"response-body\">'\n",
    "            \n",
    "            # Escape HTML but preserve line breaks\n",
    "            escaped_text = html.escape(response_text).replace('\\n', '<br>')\n",
    "            \n",
    "            # Highlight tags\n",
    "            escaped_text = re.sub(\n",
    "                r'&lt;think&gt;(.+?)&lt;/think&gt;',\n",
    "                r'<span class=\"think-tag\">&lt;think&gt;</span>\\1<span class=\"think-tag\">&lt;/think&gt;</span>',\n",
    "                escaped_text,\n",
    "                flags=re.DOTALL\n",
    "            )\n",
    "            \n",
    "            escaped_text = re.sub(\n",
    "                r'&lt;answer_era&gt;(.+?)&lt;/answer_era&gt;',\n",
    "                r'<span class=\"answer-era-tag\">&lt;answer_era&gt;</span>\\1<span class=\"answer-era-tag\">&lt;/answer_era&gt;</span>',\n",
    "                escaped_text\n",
    "            )\n",
    "            \n",
    "            escaped_text = re.sub(\n",
    "                r'&lt;answer_date&gt;(.+?)&lt;/answer_date&gt;',\n",
    "                r'<span class=\"answer-date-tag\">&lt;answer_date&gt;</span>\\1<span class=\"answer-date-tag\">&lt;/answer_date&gt;</span>',\n",
    "                escaped_text\n",
    "            )\n",
    "            \n",
    "            html_output += escaped_text\n",
    "            html_output += '</div>'  # End response body\n",
    "            \n",
    "            # Metrics container\n",
    "            if reward_value is not None or advantage_value is not None:\n",
    "                html_output += f'<div class=\"metrics-container\">'\n",
    "                \n",
    "                # Determine score class based on reward value\n",
    "                score_class = \"score-high\" if reward_value and reward_value >= 80 else \\\n",
    "                              \"score-medium\" if reward_value and reward_value >= 30 else \\\n",
    "                              \"score-low\"\n",
    "                \n",
    "                # Display reward\n",
    "                if reward_value is not None:\n",
    "                    html_output += f'<div><strong class=\"metric-label\">Reward:</strong> <span class=\"metric-score {score_class}\">{reward_value:.1f}</span></div>'\n",
    "                \n",
    "                # Display advantage\n",
    "                if advantage_value is not None:\n",
    "                    adv_class = \"score-high\" if advantage_value > 0 else \"score-low\"\n",
    "                    html_output += f'<div><strong class=\"metric-label\">Advantage:</strong> <span class=\"metric-score {adv_class}\">{advantage_value:.1f}</span></div>'\n",
    "                \n",
    "                # Add details toggle if available\n",
    "                if details is not None and b < len(details) and g < len(details[b]):\n",
    "                    html_output += f'<a id=\"toggle-{b}-{g}\" class=\"metrics-toggle\" onclick=\"toggleDetails({b}, {g})\">Show Details</a>'\n",
    "                    html_output += f'<div id=\"details-{b}-{g}\" class=\"details-container\">'\n",
    "                    \n",
    "                    # Format reward details\n",
    "                    detail_data = details[b][g]\n",
    "                    \n",
    "                    # Ground truth\n",
    "                    html_output += f'<div style=\"margin-bottom: 15px;\">'\n",
    "                    html_output += f'<div><strong>Ground Truth:</strong> Era=\\'{detail_data[\"ground_truth\"][\"era\"]}\\', Date=\\'{detail_data[\"ground_truth\"][\"date\"]}\\'</div>'\n",
    "                    html_output += f'</div>'\n",
    "                    \n",
    "                    # Extracted tags\n",
    "                    html_output += f'<div style=\"margin-bottom: 15px;\">'\n",
    "                    html_output += f'<div><strong>Extracted Tags:</strong></div>'\n",
    "                    html_output += f'<ul style=\"margin-top: 5px; padding-left: 20px;\">'\n",
    "                    html_output += f'<li>Think: {len(detail_data[\"extracted_tags\"][\"think\"])} tag(s)</li>'\n",
    "                    html_output += f'<li>Era: {len(detail_data[\"extracted_tags\"][\"answer_era\"])} tag(s)</li>'\n",
    "                    html_output += f'<li>Date: {len(detail_data[\"extracted_tags\"][\"answer_date\"])} tag(s)</li>'\n",
    "                    html_output += f'</ul>'\n",
    "                    html_output += f'</div>'\n",
    "                    \n",
    "                    # Format analysis\n",
    "                    html_output += f'<div style=\"margin-bottom: 15px;\">'\n",
    "                    html_output += f'<div><strong>Format Analysis:</strong></div>'\n",
    "                    \n",
    "                    if detail_data['format_analysis'].get('has_outside_text', False):\n",
    "                        outside_text = html.escape(detail_data['format_analysis']['outside_text'])\n",
    "                        html_output += f'<div class=\"check-fail\">❌ Text outside tags: \"{outside_text}\"</div>'\n",
    "                    else:\n",
    "                        html_output += f'<div class=\"check-success\">✓ No text outside tags</div>'\n",
    "                    \n",
    "                    html_output += f'</div>'\n",
    "                    \n",
    "                    # Content analysis\n",
    "                    if 'content_analysis' in detail_data:\n",
    "                        html_output += f'<div style=\"margin-bottom: 15px;\">'\n",
    "                        html_output += f'<div><strong>Content Analysis:</strong></div>'\n",
    "                        \n",
    "                        # Era analysis\n",
    "                        if 'era' in detail_data['content_analysis']:\n",
    "                            provided_eras = ', '.join([f\"'{era}'\" for era in detail_data['content_analysis']['era']['provided']])\n",
    "                            html_output += f'<div style=\"margin-top: 5px;\"><strong>Era provided:</strong> {provided_eras}</div>'\n",
    "                            \n",
    "                            match_status = \"\"\n",
    "                            if detail_data['content_analysis'].get('era_match', {}).get('exact_match', False):\n",
    "                                match_status = f'<span class=\"check-success\">✓ Exact match</span>'\n",
    "                            elif detail_data['content_analysis'].get('era_match', {}).get('partial_match', False):\n",
    "                                match_status = f'<span style=\"color: #BE6A1A; font-weight: bold;\">~ Partial match</span>'\n",
    "                            else:\n",
    "                                match_status = f'<span class=\"check-fail\">❌ No match</span>'\n",
    "                            \n",
    "                            html_output += f'<div><strong>Era match:</strong> {match_status}</div>'\n",
    "                        \n",
    "                        # Date analysis\n",
    "                        if 'date' in detail_data['content_analysis']:\n",
    "                            provided_dates = ', '.join([f\"'{date}'\" for date in detail_data['content_analysis']['date']['provided']])\n",
    "                            html_output += f'<div style=\"margin-top: 5px;\"><strong>Date provided:</strong> {provided_dates}</div>'\n",
    "                            \n",
    "                            if 'best_match' in detail_data['content_analysis']['date']:\n",
    "                                best = detail_data['content_analysis']['date']['best_match']\n",
    "                                diff_class = \"check-success\" if best['difference'] <= 20 else \\\n",
    "                                             (\"color: #BE6A1A; font-weight: bold;\" if best['difference'] <= 50 else \"check-fail\")\n",
    "                                \n",
    "                                html_output += f'<div><strong>Best date:</strong> {best[\"value\"]} <span style=\"{diff_class}\">(diff: {best[\"difference\"]} years)</span></div>'\n",
    "                        \n",
    "                        html_output += f'</div>'\n",
    "                    \n",
    "                    # Reward components table\n",
    "                    html_output += f'<div style=\"margin-bottom: 15px;\">'\n",
    "                    html_output += f'<div><strong>Reward Components:</strong></div>'\n",
    "                    html_output += f'<div style=\"margin-top: 10px;\">'\n",
    "                    \n",
    "                    for component in detail_data['reward_components']:\n",
    "                        component_name = component['component']\n",
    "                        value = component['value']\n",
    "                        reason = component['reason']\n",
    "                        \n",
    "                        # Determine CSS class based on value\n",
    "                        try:\n",
    "                            value_float = float(str(value).replace(\"(overwrites previous)\", \"\"))\n",
    "                            value_class = \"component-value-positive\" if value_float > 0 else \"component-value-negative\"\n",
    "                        except:\n",
    "                            value_class = \"\"\n",
    "                        \n",
    "                        html_output += f'<div class=\"reward-component\">'\n",
    "                        html_output += f'<div><span class=\"component-name\">{component_name}:</span> <span class=\"component-value {value_class}\">{value}</span></div>'\n",
    "                        html_output += f'<div class=\"component-reason\">{reason}</div>'\n",
    "                        html_output += f'</div>'\n",
    "                    \n",
    "                    html_output += f'</div>'\n",
    "                    html_output += f'</div>'\n",
    "                    \n",
    "                    # Success criteria\n",
    "                    if 'success_criteria' in detail_data:\n",
    "                        criteria = detail_data['success_criteria']\n",
    "                        html_output += f'<div style=\"margin-bottom: 15px;\">'\n",
    "                        html_output += f'<div><strong>Success Criteria:</strong></div>'\n",
    "                        html_output += f'<ul style=\"margin-top: 5px; padding-left: 20px;\">'\n",
    "                        \n",
    "                        html_output += f'<li><span class=\"{\"check-success\" if criteria[\"perfect_format\"] else \"check-fail\"}\">{(\"✓\" if criteria[\"perfect_format\"] else \"❌\")} Format perfect</span></li>'\n",
    "                        html_output += f'<li><span class=\"{\"check-success\" if criteria[\"correct_era\"] else \"check-fail\"}\">{(\"✓\" if criteria[\"correct_era\"] else \"❌\")} Era correct</span></li>'\n",
    "                        html_output += f'<li><span class=\"{\"check-success\" if criteria[\"correct_date\"] else \"check-fail\"}\">{(\"✓\" if criteria[\"correct_date\"] else \"❌\")} Date correct</span></li>'\n",
    "                        \n",
    "                        html_output += f'</ul>'\n",
    "                        html_output += f'</div>'\n",
    "                    \n",
    "                    # Total reward summary\n",
    "                    html_output += f'<div style=\"margin-top: 15px; padding-top: 10px; border-top: 1px solid #C4C7AC;\">'\n",
    "                    html_output += f'<div><strong>Total Reward:</strong> <span class=\"{\"score-high\" if detail_data[\"total_reward\"] > 0 else \"score-low\"}\">{detail_data[\"total_reward\"]}</span></div>'\n",
    "                    html_output += f'<div><strong>Success:</strong> <span class=\"{\"score-high\" if detail_data[\"success\"] > 0 else \"score-low\"}\">{detail_data[\"success\"]}</span></div>'\n",
    "                    html_output += f'</div>'\n",
    "                    \n",
    "                    html_output += f'</div>'  # End details container\n",
    "                \n",
    "                html_output += f'</div>'  # End metrics container\n",
    "            \n",
    "            html_output += f'</div>'  # End response container\n",
    "    \n",
    "    return html_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .response-container {\n",
       "            margin: 20px 0;\n",
       "            border: 1px solid #C4C7AC;\n",
       "            border-radius: 8px;\n",
       "            overflow: hidden;\n",
       "            box-shadow: 0 2px 5px rgba(0,0,0,0.05);\n",
       "            font-family: 'Courier New', monospace;\n",
       "            max-width: 100%;\n",
       "        }\n",
       "        .response-header {\n",
       "            background-color: #F0EBE5;\n",
       "            padding: 10px 15px;\n",
       "            font-size: 16px;\n",
       "            font-weight: bold;\n",
       "            border-bottom: 1px solid #C4C7AC;\n",
       "            color: #4A4A67;\n",
       "            display: flex;\n",
       "            justify-content: space-between;\n",
       "            align-items: center;\n",
       "        }\n",
       "        .response-body {\n",
       "            background-color: #ffffff;\n",
       "            color: #4A4A67;\n",
       "            padding: 15px;\n",
       "            white-space: pre-wrap;\n",
       "            word-wrap: break-word;\n",
       "            line-height: 1.6;\n",
       "            font-size: 14px;\n",
       "        }\n",
       "        .think-tag {\n",
       "            color: #BE6A1A;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .answer-tag {\n",
       "            color: #2C6846;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .answer-era-tag {\n",
       "            color: #2C6846;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .answer-date-tag {\n",
       "            color: #2C6846;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .metrics-container {\n",
       "            background-color: #F0EBE5;\n",
       "            border-top: 1px solid #C4C7AC;\n",
       "            padding: 10px 15px;\n",
       "        }\n",
       "        .metric-label {\n",
       "            color: #4A4A67;\n",
       "        }\n",
       "        .metric-score {\n",
       "            font-family: monospace;\n",
       "            font-weight: bold;\n",
       "            padding: 2px 8px;\n",
       "            border-radius: 4px;\n",
       "            display: inline-block;\n",
       "            margin-right: 8px;\n",
       "        }\n",
       "        .score-high {\n",
       "            background-color: #D3EFE0;\n",
       "            color: #177350;\n",
       "        }\n",
       "        .score-medium {\n",
       "            background-color: #FCF1D6;\n",
       "            color: #BE6A1A;\n",
       "        }\n",
       "        .score-low {\n",
       "            background-color: #FAD9D8;\n",
       "            color: #C5393A;\n",
       "        }\n",
       "        .success-badge {\n",
       "            background-color: #177350;\n",
       "            color: white;\n",
       "            padding: 3px 8px;\n",
       "            border-radius: 4px;\n",
       "            font-size: 12px;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .failure-badge {\n",
       "            background-color: #C5393A;\n",
       "            color: white;\n",
       "            padding: 3px 8px;\n",
       "            border-radius: 4px;\n",
       "            font-size: 12px;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .metrics-toggle {\n",
       "            cursor: pointer;\n",
       "            color: #3F7DC9;\n",
       "            text-decoration: underline;\n",
       "            font-size: 12px;\n",
       "            margin-top: 5px;\n",
       "            display: inline-block;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .details-container {\n",
       "            display: none;\n",
       "            margin-top: 10px;\n",
       "            border-top: 1px solid #C4C7AC;\n",
       "            padding-top: 10px;\n",
       "        }\n",
       "\n",
       "        /* Reward details styling */\n",
       "        .reward-component {\n",
       "            margin-bottom: 10px;\n",
       "            padding: 8px;\n",
       "            border-radius: 4px;\n",
       "            background-color: #f8f9fa;\n",
       "        }\n",
       "        .component-name {\n",
       "            font-weight: bold;\n",
       "            color: #4A4A67;\n",
       "        }\n",
       "        .component-value {\n",
       "            font-family: monospace;\n",
       "            padding: 2px 4px;\n",
       "            border-radius: 3px;\n",
       "        }\n",
       "        .component-value-positive {\n",
       "            background-color: #D3EFE0;\n",
       "            color: #177350;\n",
       "        }\n",
       "        .component-value-negative {\n",
       "            background-color: #FAD9D8;\n",
       "            color: #C5393A;\n",
       "        }\n",
       "        .component-reason {\n",
       "            font-size: 0.9em;\n",
       "            color: #555;\n",
       "            margin-top: 4px;\n",
       "        }\n",
       "        .check-success {\n",
       "            color: #177350;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .check-fail {\n",
       "            color: #C5393A;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .batch-header {\n",
       "            margin: 30px 0 10px 0;\n",
       "            padding: 5px 10px;\n",
       "            background-color: #E5E7D9;\n",
       "            border-left: 4px solid #4A4A67;\n",
       "            color: #4A4A67;\n",
       "            font-size: 18px;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "    </style>\n",
       "\n",
       "    <script>\n",
       "    function toggleDetails(batchIdx, groupIdx) {\n",
       "        var detailsId = 'details-' + batchIdx + '-' + groupIdx;\n",
       "        var details = document.getElementById(detailsId);\n",
       "        var buttonId = 'toggle-' + batchIdx + '-' + groupIdx;\n",
       "        var toggleBtn = document.getElementById(buttonId);\n",
       "\n",
       "        if (details) {\n",
       "            if (details.style.display === 'none' || details.style.display === '') {\n",
       "                details.style.display = 'block';\n",
       "                if (toggleBtn) toggleBtn.innerText = 'Hide Details';\n",
       "            } else {\n",
       "                details.style.display = 'none';\n",
       "                if (toggleBtn) toggleBtn.innerText = 'Show Details';\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "    </script>\n",
       "    <div class=\"batch-header\">Batch #1</div><div class=\"response-container\"><div class=\"response-header\"><div>Response #1</div><div class=\"failure-badge\">FAIL</div></div><div class=\"response-body\"> <span class=\"think-tag\">&lt;think&gt;</span>The language and style used in this passage are reminiscent of Shakespeare&#x27;s plays, particularly Romeo and Juliet. The formal, poetic, and somewhat archaic language suggests a 16th-century or 17th-century context. The mention of specific characters and events, such as Romeo and Juliet, and the mention of Lord Capulet and Tybalt, also indicate a Renaissance-era setting. Additionally, the use of phrases like &quot;beshrew my very heart&quot; and &quot;Ancient damnation&quot; which were common in Early Modern English, supports this conclusion. The passage is likely from a play written during the Renaissance era, likely between 1595 and 1613, which is consistent with the style of Shakespeare&#x27;s plays.<span class=\"think-tag\">&lt;/think&gt;</span> <span class=\"answer-date-tag\">&lt;answer_date&gt;</span>1600<span class=\"answer-date-tag\">&lt;/answer_date&gt;</span> <span class=\"answer-era-tag\">&lt;answer_era&gt;</span>renaissance<span class=\"answer-era-tag\">&lt;/answer_era&gt;</span></div><div class=\"metrics-container\"><div><strong class=\"metric-label\">Reward:</strong> <span class=\"metric-score score-medium\">75.0</span></div><div><strong class=\"metric-label\">Advantage:</strong> <span class=\"metric-score score-high\">0.7</span></div><a id=\"toggle-0-0\" class=\"metrics-toggle\" onclick=\"toggleDetails(0, 0)\">Show Details</a><div id=\"details-0-0\" class=\"details-container\"><div style=\"margin-bottom: 15px;\"><div><strong>Ground Truth:</strong> Era='renaissance', Date='1575'</div></div><div style=\"margin-bottom: 15px;\"><div><strong>Extracted Tags:</strong></div><ul style=\"margin-top: 5px; padding-left: 20px;\"><li>Think: 1 tag(s)</li><li>Era: 1 tag(s)</li><li>Date: 1 tag(s)</li></ul></div><div style=\"margin-bottom: 15px;\"><div><strong>Format Analysis:</strong></div><div class=\"check-success\">✓ No text outside tags</div></div><div style=\"margin-bottom: 15px;\"><div><strong>Content Analysis:</strong></div><div style=\"margin-top: 5px;\"><strong>Era provided:</strong> 'renaissance'</div><div><strong>Era match:</strong> <span class=\"check-success\">✓ Exact match</span></div><div style=\"margin-top: 5px;\"><strong>Date provided:</strong> '1600'</div><div><strong>Best date:</strong> 1600 <span style=\"color: #BE6A1A; font-weight: bold;\">(diff: 25 years)</span></div></div><div style=\"margin-bottom: 15px;\"><div><strong>Reward Components:</strong></div><div style=\"margin-top: 10px;\"><div class=\"reward-component\"><div><span class=\"component-name\">think_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <think> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <answer_era> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">date_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <answer_date> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_validation:</span> <span class=\"component-value component-value-positive\">5.0</span></div><div class=\"component-reason\">Used valid era(s): renaissance</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_correctness:</span> <span class=\"component-value component-value-positive\">30.0</span></div><div class=\"component-reason\">Correct era: renaissance</div></div><div class=\"reward-component\"><div><span class=\"component-name\">date_correctness:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Approximate date: 1600 (within 50 years of 1575)</div></div></div></div><div style=\"margin-bottom: 15px;\"><div><strong>Success Criteria:</strong></div><ul style=\"margin-top: 5px; padding-left: 20px;\"><li><span class=\"check-success\">✓ Format perfect</span></li><li><span class=\"check-success\">✓ Era correct</span></li><li><span class=\"check-fail\">❌ Date correct</span></li></ul></div><div style=\"margin-top: 15px; padding-top: 10px; border-top: 1px solid #C4C7AC;\"><div><strong>Total Reward:</strong> <span class=\"score-high\">75.0</span></div><div><strong>Success:</strong> <span class=\"score-low\">0.0</span></div></div></div></div></div><div class=\"response-container\"><div class=\"response-header\"><div>Response #2</div><div class=\"failure-badge\">FAIL</div></div><div class=\"response-body\"> <span class=\"think-tag\">&lt;think&gt;</span>Based on the passage, I can identify certain elements that hint at the time period in which the play takes place. Firstly, the use of Early Modern English (EME) features such as &quot;thou,&quot; &quot;thee,&quot; &quot;doth,&quot; &quot;hath,&quot; and &quot;verily&quot; are indicative of the 16th or 17th century, but in this case, I notice the more formal and poetic language used in the dialogue, which is more typical of the Elizabethan or Jacobean periods. Furthermore, the mention of specific societal norms and customs, such as the engagement to marry Paris after Juliet&#x27;s initial rejection and the emphasis on the societal pressure to maintain family honor, suggests that the play is set in the late 16th century, which was the Elizabethan era. The reference to a Friar and the Catholic Church also points towards this era. The lack of specific time references, such as a year or month, makes it a bit challenging to pinpoint an exact date. However, based on the linguistic and cultural cues, I would place the play&#x27;s setting in the late Elizabethan period, approximately between 1590 and 1600.<span class=\"think-tag\">&lt;/think&gt;</span> <span class=\"answer-date-tag\">&lt;answer_date&gt;</span>1590<span class=\"answer-date-tag\">&lt;/answer_date&gt;</span> <span class=\"answer-era-tag\">&lt;answer_era&gt;</span>elizabethan<span class=\"answer-era-tag\">&lt;/answer_era&gt;</span></div><div class=\"metrics-container\"><div><strong class=\"metric-label\">Reward:</strong> <span class=\"metric-score score-medium\">45.0</span></div><div><strong class=\"metric-label\">Advantage:</strong> <span class=\"metric-score score-low\">-0.7</span></div><a id=\"toggle-0-1\" class=\"metrics-toggle\" onclick=\"toggleDetails(0, 1)\">Show Details</a><div id=\"details-0-1\" class=\"details-container\"><div style=\"margin-bottom: 15px;\"><div><strong>Ground Truth:</strong> Era='renaissance', Date='1575'</div></div><div style=\"margin-bottom: 15px;\"><div><strong>Extracted Tags:</strong></div><ul style=\"margin-top: 5px; padding-left: 20px;\"><li>Think: 1 tag(s)</li><li>Era: 1 tag(s)</li><li>Date: 1 tag(s)</li></ul></div><div style=\"margin-bottom: 15px;\"><div><strong>Format Analysis:</strong></div><div class=\"check-success\">✓ No text outside tags</div></div><div style=\"margin-bottom: 15px;\"><div><strong>Content Analysis:</strong></div><div style=\"margin-top: 5px;\"><strong>Era provided:</strong> 'elizabethan'</div><div><strong>Era match:</strong> <span class=\"check-fail\">❌ No match</span></div><div style=\"margin-top: 5px;\"><strong>Date provided:</strong> '1590'</div><div><strong>Best date:</strong> 1590 <span style=\"check-success\">(diff: 15 years)</span></div></div><div style=\"margin-bottom: 15px;\"><div><strong>Reward Components:</strong></div><div style=\"margin-top: 10px;\"><div class=\"reward-component\"><div><span class=\"component-name\">think_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <think> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <answer_era> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">date_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <answer_date> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_validation:</span> <span class=\"component-value component-value-negative\">-5.0</span></div><div class=\"component-reason\">Invalid era(s): elizabethan</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_correctness:</span> <span class=\"component-value component-value-negative\">0.0</span></div><div class=\"component-reason\">Incorrect era: Expected 'renaissance'</div></div><div class=\"reward-component\"><div><span class=\"component-name\">date_correctness:</span> <span class=\"component-value component-value-positive\">20.0</span></div><div class=\"component-reason\">Close date match: 1590 (within 20 years of 1575)</div></div></div></div><div style=\"margin-bottom: 15px;\"><div><strong>Success Criteria:</strong></div><ul style=\"margin-top: 5px; padding-left: 20px;\"><li><span class=\"check-success\">✓ Format perfect</span></li><li><span class=\"check-fail\">❌ Era correct</span></li><li><span class=\"check-success\">✓ Date correct</span></li></ul></div><div style=\"margin-top: 15px; padding-top: 10px; border-top: 1px solid #C4C7AC;\"><div><strong>Total Reward:</strong> <span class=\"score-high\">45.0</span></div><div><strong>Success:</strong> <span class=\"score-low\">0.0</span></div></div></div></div></div><div class=\"batch-header\">Batch #2</div><div class=\"response-container\"><div class=\"response-header\"><div>Response #1</div><div class=\"failure-badge\">FAIL</div></div><div class=\"response-body\"> <span class=\"think-tag\">&lt;think&gt;</span>This passage uses a formal and somewhat archaic writing style, reminiscent of 18th or early 19th century works such as those of Frances Burney or Henry Fielding. The use of phrases like &quot;I know not why&quot; and &quot;I was astonished&quot; suggests a time period when formal, polite language was the norm. Furthermore, the name &quot;Luscinda&quot; has a distinctly Italianate or Mediterranean feel to it, which is consistent with the time period of the late 18th century or early 19th century. The fact that the passage does not contain any overtly modern references or themes, such as industrialization, technological advancements, or social change, also suggests a historical era prior to the Victorian period. <span class=\"think-tag\">&lt;/think&gt;</span> <span class=\"answer-date-tag\">&lt;answer_date&gt;</span>1790<span class=\"answer-date-tag\">&lt;/answer_date&gt;</span> <span class=\"answer-era-tag\">&lt;answer_era&gt;</span>georgian<span class=\"answer-era-tag\">&lt;/answer_era&gt;</span></div><div class=\"metrics-container\"><div><strong class=\"metric-label\">Reward:</strong> <span class=\"metric-score score-low\">20.0</span></div><div><strong class=\"metric-label\">Advantage:</strong> <span class=\"metric-score score-low\">-0.7</span></div><a id=\"toggle-1-0\" class=\"metrics-toggle\" onclick=\"toggleDetails(1, 0)\">Show Details</a><div id=\"details-1-0\" class=\"details-container\"><div style=\"margin-bottom: 15px;\"><div><strong>Ground Truth:</strong> Era='renaissance', Date='1575'</div></div><div style=\"margin-bottom: 15px;\"><div><strong>Extracted Tags:</strong></div><ul style=\"margin-top: 5px; padding-left: 20px;\"><li>Think: 1 tag(s)</li><li>Era: 1 tag(s)</li><li>Date: 1 tag(s)</li></ul></div><div style=\"margin-bottom: 15px;\"><div><strong>Format Analysis:</strong></div><div class=\"check-success\">✓ No text outside tags</div></div><div style=\"margin-bottom: 15px;\"><div><strong>Content Analysis:</strong></div><div style=\"margin-top: 5px;\"><strong>Era provided:</strong> 'georgian'</div><div><strong>Era match:</strong> <span class=\"check-fail\">❌ No match</span></div><div style=\"margin-top: 5px;\"><strong>Date provided:</strong> '1790'</div><div><strong>Best date:</strong> 1790 <span style=\"check-fail\">(diff: 215 years)</span></div></div><div style=\"margin-bottom: 15px;\"><div><strong>Reward Components:</strong></div><div style=\"margin-top: 10px;\"><div class=\"reward-component\"><div><span class=\"component-name\">think_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <think> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <answer_era> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">date_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <answer_date> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_validation:</span> <span class=\"component-value component-value-negative\">-5.0</span></div><div class=\"component-reason\">Invalid era(s): georgian</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_correctness:</span> <span class=\"component-value component-value-negative\">0.0</span></div><div class=\"component-reason\">Incorrect era: Expected 'renaissance'</div></div><div class=\"reward-component\"><div><span class=\"component-name\">date_correctness:</span> <span class=\"component-value component-value-negative\">-5.0</span></div><div class=\"component-reason\">Incorrect date: 1790 (more than 100 years from 1575)</div></div></div></div><div style=\"margin-bottom: 15px;\"><div><strong>Success Criteria:</strong></div><ul style=\"margin-top: 5px; padding-left: 20px;\"><li><span class=\"check-success\">✓ Format perfect</span></li><li><span class=\"check-fail\">❌ Era correct</span></li><li><span class=\"check-fail\">❌ Date correct</span></li></ul></div><div style=\"margin-top: 15px; padding-top: 10px; border-top: 1px solid #C4C7AC;\"><div><strong>Total Reward:</strong> <span class=\"score-high\">20.0</span></div><div><strong>Success:</strong> <span class=\"score-low\">0.0</span></div></div></div></div></div><div class=\"response-container\"><div class=\"response-header\"><div>Response #2</div><div class=\"failure-badge\">FAIL</div></div><div class=\"response-body\"> <span class=\"think-tag\">&lt;think&gt;</span>The passage is written in a style reminiscent of 18th-century literature, specifically the romantic era, with features such as formal language, elaborate metaphors, and a focus on emotional and psychological states. The protagonist&#x27;s tone is one of wistful melancholy, and the narrative is peppered with poetic descriptions of nature and the emotions of the characters. The language used is dense and elaborate, which is typical of 18th-century writers like Alexander Pope or Henry Fielding. The use of words like &quot;inferral&quot; and &quot;treachery&quot; suggests a level of formality and antiquity that is also characteristic of the 18th century. The protagonist&#x27;s relationship with Luscinda is portrayed as being deeply emotional and intimate, with a focus on the speaker&#x27;s feelings and emotions. The overall tone of the passage is one of nostalgia and longing, with the speaker reflecting on past experiences and relationships. Based on these features, I would place the historical era of this passage in the Enlightenment era, circa 1750-1760, although it is possible that it could be from the earlier 18th century or even the 17th century, depending on the specific literary style and language used.<span class=\"think-tag\">&lt;/think&gt;</span> <span class=\"answer-date-tag\">&lt;answer_date&gt;</span>1720<span class=\"answer-date-tag\">&lt;/answer_date&gt;</span> <span class=\"answer-era-tag\">&lt;answer_era&gt;</span>enlightenment<span class=\"answer-era-tag\">&lt;/answer_era&gt;</span></div><div class=\"metrics-container\"><div><strong class=\"metric-label\">Reward:</strong> <span class=\"metric-score score-medium\">30.0</span></div><div><strong class=\"metric-label\">Advantage:</strong> <span class=\"metric-score score-high\">0.7</span></div><a id=\"toggle-1-1\" class=\"metrics-toggle\" onclick=\"toggleDetails(1, 1)\">Show Details</a><div id=\"details-1-1\" class=\"details-container\"><div style=\"margin-bottom: 15px;\"><div><strong>Ground Truth:</strong> Era='renaissance', Date='1575'</div></div><div style=\"margin-bottom: 15px;\"><div><strong>Extracted Tags:</strong></div><ul style=\"margin-top: 5px; padding-left: 20px;\"><li>Think: 1 tag(s)</li><li>Era: 1 tag(s)</li><li>Date: 1 tag(s)</li></ul></div><div style=\"margin-bottom: 15px;\"><div><strong>Format Analysis:</strong></div><div class=\"check-success\">✓ No text outside tags</div></div><div style=\"margin-bottom: 15px;\"><div><strong>Content Analysis:</strong></div><div style=\"margin-top: 5px;\"><strong>Era provided:</strong> 'enlightenment'</div><div><strong>Era match:</strong> <span class=\"check-fail\">❌ No match</span></div><div style=\"margin-top: 5px;\"><strong>Date provided:</strong> '1720'</div><div><strong>Best date:</strong> 1720 <span style=\"check-fail\">(diff: 145 years)</span></div></div><div style=\"margin-bottom: 15px;\"><div><strong>Reward Components:</strong></div><div style=\"margin-top: 10px;\"><div class=\"reward-component\"><div><span class=\"component-name\">think_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <think> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <answer_era> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">date_tag_format:</span> <span class=\"component-value component-value-positive\">10.0</span></div><div class=\"component-reason\">Correct: Exactly one <answer_date> tag</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_validation:</span> <span class=\"component-value component-value-positive\">5.0</span></div><div class=\"component-reason\">Used valid era(s): enlightenment</div></div><div class=\"reward-component\"><div><span class=\"component-name\">era_correctness:</span> <span class=\"component-value component-value-negative\">0.0</span></div><div class=\"component-reason\">Incorrect era: Expected 'renaissance'</div></div><div class=\"reward-component\"><div><span class=\"component-name\">date_correctness:</span> <span class=\"component-value component-value-negative\">-5.0</span></div><div class=\"component-reason\">Incorrect date: 1720 (more than 100 years from 1575)</div></div></div></div><div style=\"margin-bottom: 15px;\"><div><strong>Success Criteria:</strong></div><ul style=\"margin-top: 5px; padding-left: 20px;\"><li><span class=\"check-success\">✓ Format perfect</span></li><li><span class=\"check-fail\">❌ Era correct</span></li><li><span class=\"check-fail\">❌ Date correct</span></li></ul></div><div style=\"margin-top: 15px; padding-top: 10px; border-top: 1px solid #C4C7AC;\"><div><strong>Total Reward:</strong> <span class=\"score-high\">30.0</span></div><div><strong>Success:</strong> <span class=\"score-low\">0.0</span></div></div></div></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\n",
    "    display_responses(\n",
    "        responses,\n",
    "        tokenizer, \n",
    "        grpo_size, \n",
    "        advantages=advantages, \n",
    "        rewards=rewards, \n",
    "        successes=successes,\n",
    "        details=details # OPTIONAL\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
